{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model with _Bike Rental Data_ using XGBoost\n",
    "\n",
    "This section will work with XGBoost as a local installation to the instance.\n",
    "\n",
    "## Training _log1p(count)_ onto Dataset\n",
    "\n",
    "**Kernel used:** Conda with TensorFlow Python 3.6.5 for Amazon Elastic Instance *(conda_amazonei_tensorflow_p36)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First update *conda* and *pip* to latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda update -n base conda\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure required packages are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list nb_conda\n",
    "!conda list numpy\n",
    "!conda list pandas\n",
    "!conda list pip\n",
    "!conda list python\n",
    "!conda list matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major Library Versions Used\n",
    "\n",
    "| Library | Version |\n",
    "|---------|:--------|\n",
    "| nb_conda | 2.2.1 |\n",
    "| matplotlib | 3.0.3 |\n",
    "| numpy | 1.17.4 |\n",
    "| pandas | 0.24.2 |\n",
    "| pip | 20.2 |\n",
    "| python | 3.6.5 |\n",
    "| xgboost | 0.90 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Files from Data Preparation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_file = 'bikeTrain_column_listv2.txt'\n",
    "train_file = 'bikeTrainingv2.csv'\n",
    "validation_file ='bikeValidationv2.csv'\n",
    "test_file ='bikeTestv2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = '' # setup columns variable as empty string\n",
    "with open(column_list_file,'r') as f:\n",
    "    columns = f.read().split(',') # columns read from text file containing CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns # data check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Column Names as the File Does Not Have Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_file, names=columns)\n",
    "df_validation = pd.read_csv(validation_file,names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.head() # data check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Features and Targets for Training and Validation\n",
    "This is in preparation for use in XGBoost's regressor\n",
    "*Note: Remember that Python indices start at 0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:] # Features: Seconds [1] Column to the end\n",
    "y_train = df_train.iloc[:,0].ravel() # Target is the first column [0]th\n",
    "\n",
    "x_validation = df_validation.iloc[:,1:] # Features: Seconds [1] Column to the end\n",
    "y_validation = df_validation.iloc[:,0].ravel() # Target is the first column [0]th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up XGBoost Regressor\n",
    "\n",
    "Below cells will set up the training instance, set the hyperparameters, and then fit the model to the training data.\n",
    "\n",
    "Find Distributed (Deep) Machine Learning Community's XGBoost Training Parameter Reference [here](https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst)\n",
    "\n",
    "In this project, I updated the following parameters:\n",
    "```reg:squarederror``` as ```reg:linear``` is deprecated.\n",
    "\n",
    "Additionally, I am to add my tuning to the _XGBoost_ Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regressor\n",
    "# XGBoost Training Parameters Reference:\n",
    "# https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst\n",
    "# Limited the depth to 5 vice 6.\n",
    "# n_estimators helps tune the number of Decision Trees in XGBoost\n",
    "\n",
    "regressor = xgb.XGBRegressor(max_depth=5, n_estimators=200, objective='reg:squarederror')\n",
    "# n_estimators at 150, 200 over to 250 results in little additional log loss reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor # display hyperparameters. This is my habit to ensure my settings are correct \\\\\n",
    "# before I run a regressor. Note: This will display at the end of the training model process, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(x_train, y_train, eval_set = [(x_train, y_train), (x_validation, y_validation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = regressor.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rounds = range(len(eval_result['validation_0']['rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_rounds) # check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Training vs. Validation Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=training_rounds, y=eval_result['validation_0']['rmse'], label='Training Error')\n",
    "plt.scatter(x=training_rounds, y=eval_result['validation_1']['rmse'], label='Validation Error')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training Vs. Validation Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Feature Importance\n",
    "By default, the graph displays as a horiztonal bar with counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(regressor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Quality using Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(validation_file,names=columns)\n",
    "# compare actual vs. predicted performance with dataset not seen by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # display a tuple that represents Dataframe's dimensionality (columns, rows, depth, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df.iloc[:,1:]\n",
    "print(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_predicted'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # new column at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Values can appear in predictions\n",
    "Displayed through _pandas_ DataFrame Describe function\n",
    "\n",
    "_Generate descriptive statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding All Negative Values for Zeroizing\n",
    "Sometimes, regressors predict values that do not match the problem's context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_predicted'].hist()\n",
    "plt.title('Predicted Count Histogram')\n",
    "plt.show()\n",
    "# There are values below 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['count_predicted'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There are no values below 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the Count to Just Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_count(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_predicted'] = df['count_predicted'].map(adjust_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['count_predicted'] < 0] # double-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = df['count'].map(np.expm1)\n",
    "df['count_predicted'] = df['count_predicted'].map(np.expm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Actual vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['count'], label='Actual')\n",
    "plt.plot(df['count_predicted'], label='Predicted')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Rental Count')\n",
    "plt.xlim([100,150])\n",
    "plt.title('Validation Dataset: Predicted vs. Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over prediction and Under Prediction needs to be balanced\n",
    "# Training Data Residuals\n",
    "residuals = (df['count'] - df['count_predicted'])\n",
    "\n",
    "plt.hist(residuals)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Actual - Predicted')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Residuals Distribution')\n",
    "plt.axvline(color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = (residuals > 0).value_counts(sort=False)\n",
    "print(' Under Estimation: {0:0.2f}'.format(value_counts[True]/len(residuals)))\n",
    "print(' Over  Estimation: {0:0.2f}'.format(value_counts[False]/len(residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Metrics of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Model's RMSE\n",
    "print(\"Model's RMSE: {0:0.2f}\".format(mean_squared_error(df['count'],df['count_predicted'])**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSlE - Root Mean Squared Log Error\n",
    "# RMSLE Metric is used by Kaggle\n",
    "\n",
    "# RMSE Cost Function - Magnitude of difference matters\n",
    "\n",
    "# RMSLE cost function - \"Only Percentage difference matters\"\n",
    "\n",
    "# Reference:Katerina Malahova, Khor SoonHin \n",
    "# https://www.slideshare.net/KhorSoonHin/rmsle-cost-function\n",
    "def compute_rmsle(y_true, y_pred):\n",
    "    if type(y_true) != np.ndarray:\n",
    "        y_true = np.array(y_true)\n",
    "        \n",
    "    if type(y_pred) != np.ndarray:\n",
    "        y_pred = np.array(y_pred)\n",
    "     \n",
    "    return(np.average((np.log1p(y_pred) - np.log1p(y_true))**2)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE: {0:.2f}'.format(compute_rmsle(df['count'], df['count_predicted'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_file,parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =  df_test.iloc[:,1:] # Exclude datetime for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expm1(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['count'] = np.expm1(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test['count']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['datetime','count']].to_csv('predicted_countv2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
