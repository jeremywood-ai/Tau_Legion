{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization Machine - Cloud Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define IAM Role for AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "# SageMaker SDK Documentation: http://sagemaker.readthedocs.io/en/latest/estimators.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your bucket name\n",
    "bucket_name = 's3-2-ml-sagemaker'\n",
    "training_file_key = 'movie/user_movie_train.recordio'\n",
    "test_file_key = 'movie/user_movie_test.recordio'\n",
    "\n",
    "s3_model_output_location = r's3://{0}/movie/model'.format(bucket_name)\n",
    "s3_training_file_location = r's3://{0}/{1}'.format(bucket_name,training_file_key)\n",
    "s3_test_file_location = r's3://{0}/{1}'.format(bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dimensions\n",
    "\n",
    "Number of unique users + Number of unique movies in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_movie = 0\n",
    "\n",
    "# Update movie dimension - from training file\n",
    "with open(r'ml-latest-small/movie_dimension.txt','r') as f:\n",
    "    dim_movie = int(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_movie # data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://s3-2-ml-sagemaker/movie/model\n",
      "s3://s3-2-ml-sagemaker/movie/user_movie_train.recordio\n",
      "s3://s3-2-ml-sagemaker/movie/user_movie_test.recordio\n"
     ]
    }
   ],
   "source": [
    "print(s3_model_output_location)\n",
    "print(s3_training_file_location)\n",
    "print(s3_test_file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing and reading from S3 Bucket\n",
    "\n",
    "Ref: [Boto3 Read Docs](http://boto3.readthedocs.io/en/latest/guide/s3.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f: # read as binary mode\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3(r'ml-latest-small/user_movie_train.recordio',bucket_name,training_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3(r'ml-latest-small/user_movie_test.recordio',bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Algorithm Docker Image\n",
    "\n",
    "### AWS Maintains a separate image for every region and algorithm\n",
    "\n",
    "This allows quick deployment machines ready for the task.\n",
    "\n",
    "Registry Path for algorithms by SageMaker\n",
    "[Latest Dockers](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Algorithms that are parallelizable can be deployed on multiple compute instances for distributed training. For the Training Image and Inference Image Registry Path column, use the :1 version tag to ensure that you are using a stable version of the algorithm. You can reliably host a model trained using an image with the :1 tag on an inference image that has the :1 tag. Using the :latest tag in the registry path provides you with the most up-to-date version of the algorithm, but might cause problems with backward compatibility. Avoid using the :latest tag for production purposes.\" - [AWS SageMaker Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html)\n",
    "\n",
    "- First run will be using only one Docker.\n",
    "- Next run will allow more, say a six-pack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us-east-2 : 404615174143.dkr.ecr.us-east-2.amazonaws.com\n",
    "# us-east-1 : 382416733822.dkr.ecr.us-east-1.amazonaws.com\n",
    "\n",
    "containers = {'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/factorization-machines:latest',\n",
    "             'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:latest',\n",
    "             'us-west-1': '632365934929.dkr.ecr.us-west-1.amazonaws.com/factorization-machines:latest',\n",
    "             'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/factorization-machines:latest',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::399426528351:role/service-role/AmazonSageMaker-ExecutionRole-20200203T173955\n"
     ]
    }
   ],
   "source": [
    "# This role contains the permissions needed to train, deploy models\n",
    "# SageMaker Service is trusted to assume this role\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access appropriate algorithm container image\n",
    "#  Specify how many instances to use for distributed training and what type of machine to use\n",
    "#  Finally, specify where the trained model artifacts needs to be stored\n",
    "#   Reference: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "#    Optionally, give a name to the training job using base_job_name\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.m4.xlarge',\n",
    "                                       output_path=s3_model_output_location,\n",
    "                                       sagemaker_session=sess,\n",
    "                                       base_job_name ='fm-movie-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nestimator.set_hyperparameters(feature_dim=dim_movie,\\n                              num_factors=8,\\n                              predictor_type='regressor', \\n                              mini_batch_size=1000,\\n                              epochs=100)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This was the original set of hyperparameters that was used. TEST RMSE was 0.89\n",
    "# Movie lens dataset was updated recently and these parameters are no longer sufficient to produce\n",
    "# quality predictions. With new dataset, TEST RMSE is around 1.9\n",
    "# Refer to next cell for new settings\n",
    "'''\n",
    "estimator.set_hyperparameters(feature_dim=dim_movie,\n",
    "                              num_factors=8,\n",
    "                              predictor_type='regressor', \n",
    "                              mini_batch_size=1000,\n",
    "                              epochs=100)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Configuration after Model Tuning\n",
    "# Refer to Hyperparameter Tuning Section on how to optimize hyperparameters\n",
    "estimator.set_hyperparameters(feature_dim=dim_movie,\n",
    "                              num_factors=8,\n",
    "                              predictor_type='regressor', \n",
    "                              mini_batch_size=994,\n",
    "                              epochs=91,\n",
    "                              bias_init_method='normal',\n",
    "                              bias_lr=0.21899531189430518,\n",
    "                              factors_init_method='normal',\n",
    "                              factors_lr=5.357593337770278e-05,\n",
    "                              linear_init_method='normal',\n",
    "                              linear_lr=0.00021524948053767607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 10334,\n",
       " 'num_factors': 8,\n",
       " 'predictor_type': 'regressor',\n",
       " 'mini_batch_size': 994,\n",
       " 'epochs': 91,\n",
       " 'bias_init_method': 'normal',\n",
       " 'bias_lr': 0.21899531189430518,\n",
       " 'factors_init_method': 'normal',\n",
       " 'factors_lr': 5.357593337770278e-05,\n",
       " 'linear_init_method': 'normal',\n",
       " 'linear_lr': 0.00021524948053767607}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:47:03 Starting - Starting the training job...\n",
      "2020-04-20 01:47:04 Starting - Launching requested ML instances...\n",
      "2020-04-20 01:48:01 Starting - Preparing the instances for training.........\n",
      "2020-04-20 01:49:11 Downloading - Downloading input data...\n",
      "2020-04-20 01:50:02 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'predictor_type': u'regressor', u'factors_lr': u'5.357593337770278e-05', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'epochs': u'91', u'linear_lr': u'0.00021524948053767607', u'feature_dim': u'10334', u'bias_lr': u'0.21899531189430518', u'factors_init_method': u'normal', u'num_factors': u'8', u'mini_batch_size': u'994'}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] Final configuration: {u'factors_lr': u'5.357593337770278e-05', u'linear_init_sigma': u'0.01', u'epochs': u'91', u'feature_dim': u'10334', u'num_factors': u'8', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.00021524948053767607', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.21899531189430518', u'mini_batch_size': u'994', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 WARNING 140015383648064] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] Using default worker.\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:04.128] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:04.133] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 11, \"num_examples\": 1, \"num_bytes\": 63616}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] nvidia-smi took: 0.0251879692078 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 36.839962005615234, \"sum\": 36.839962005615234, \"min\": 36.839962005615234}}, \"EndTime\": 1587347404.169342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347404.12225}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 994, \"sum\": 994.0, \"min\": 994}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 994, \"sum\": 994.0, \"min\": 994}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587347404.169592, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347404.16953}\n",
      "\u001b[0m\n",
      "\u001b[34m[01:50:04] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202841.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[01:50:04] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202841.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.69335891676\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=13.640900088\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.54139780087\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:04.526] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 332, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.52218752747\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=0, train mse <loss>=2.31705486878\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.15293863895\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"update.time\": {\"count\": 1, \"max\": 357.58399963378906, \"sum\": 357.58399963378906, \"min\": 357.58399963378906}}, \"EndTime\": 1587347404.527424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347404.169452}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 73, \"sum\": 73.0, \"min\": 73}, \"Total Records Seen\": {\"count\": 1, \"max\": 71579, \"sum\": 71579.0, \"min\": 71579}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1587347404.527724, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1587347404.169801}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=197132.880083 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.05502593497\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.11307972346\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.855960224236\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:04.887] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 356, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.11829382809\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.25058108594\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.880092219168\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 360.08596420288086, \"sum\": 360.08596420288086, \"min\": 360.08596420288086}}, \"EndTime\": 1587347404.888147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347404.527531}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 145, \"sum\": 145.0, \"min\": 145}, \"Total Records Seen\": {\"count\": 1, \"max\": 142164, \"sum\": 142164.0, \"min\": 142164}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1587347404.888638, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1587347404.52802}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=195606.507361 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.05901082426\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.1215039259\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:04 INFO 140015383648064] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.86679396447\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:05.310] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 419, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.11910035629\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.25238560745\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.8800459149\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 422.37401008605957, \"sum\": 422.37401008605957, \"min\": 422.37401008605957}}, \"EndTime\": 1587347405.311558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347404.888319}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 217, \"sum\": 217.0, \"min\": 217}, \"Total Records Seen\": {\"count\": 1, \"max\": 212749, \"sum\": 212749.0, \"min\": 212749}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1587347405.311847, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1587347404.889144}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=166918.471987 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.05973361329\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.12303533113\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.870267933283\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:05.687] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 373, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.1170214062\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.2477368219\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.877613571648\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 375.76794624328613, \"sum\": 375.76794624328613, \"min\": 375.76794624328613}}, \"EndTime\": 1587347405.687976, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347405.311656}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 289, \"sum\": 289.0, \"min\": 289}, \"Total Records Seen\": {\"count\": 1, \"max\": 283334, \"sum\": 283334.0, \"min\": 283334}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1587347405.688259, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1587347405.312171}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=187606.307624 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.06039644162\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.12444061341\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:05 INFO 140015383648064] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.872994129327\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:06.039] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 348, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.11419897822\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.24143936307\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.87483129964\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 351.3801097869873, \"sum\": 351.3801097869873, \"min\": 351.3801097869873}}, \"EndTime\": 1587347406.039977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347405.688065}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 361, \"sum\": 361.0, \"min\": 361}, \"Total Records Seen\": {\"count\": 1, \"max\": 353919, \"sum\": 353919.0, \"min\": 353919}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1587347406.040205, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1587347405.688563}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=200655.498357 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.0595209431\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.12258462887\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.873270875252\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:06.377] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 335, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.11096970839\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.23425369297\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.871875722004\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 337.2631072998047, \"sum\": 337.2631072998047, \"min\": 337.2631072998047}}, \"EndTime\": 1587347406.377742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347406.040058}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 433, \"sum\": 433.0, \"min\": 433}, \"Total Records Seen\": {\"count\": 1, \"max\": 424504, \"sum\": 424504.0, \"min\": 424504}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1587347406.378013, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1587347406.040442}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=209005.142154 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.05734996075\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.1179889395\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.871761759522\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:06.731] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 351, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.10756806146\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.22670701076\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.868818565793\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 353.35516929626465, \"sum\": 353.35516929626465, \"min\": 353.35516929626465}}, \"EndTime\": 1587347406.731701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347406.37783}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 505, \"sum\": 505.0, \"min\": 505}, \"Total Records Seen\": {\"count\": 1, \"max\": 495089, \"sum\": 495089.0, \"min\": 495089}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1587347406.731932, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1587347406.378313}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=199536.936355 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.05439758432\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.11175426583\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:06 INFO 140015383648064] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.869227940888\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:07.071] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 337, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.10410710668\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.21905250302\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.86569912077\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 340.1648998260498, \"sum\": 340.1648998260498, \"min\": 340.1648998260498}}, \"EndTime\": 1587347407.072367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347406.731785}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 577, \"sum\": 577.0, \"min\": 577}, \"Total Records Seen\": {\"count\": 1, \"max\": 565674, \"sum\": 565674.0, \"min\": 565674}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1587347407.072753, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1587347406.732168}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=207128.333353 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.05102114671\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.10464545083\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.866134551449\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:07.446] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 371, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.10063494662\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.21139728573\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.862549616138\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 374.1309642791748, \"sum\": 374.1309642791748, \"min\": 374.1309642791748}}, \"EndTime\": 1587347407.447347, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347407.072508}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 649, \"sum\": 649.0, \"min\": 649}, \"Total Records Seen\": {\"count\": 1, \"max\": 636259, \"sum\": 636259.0, \"min\": 636259}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1587347407.447807, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1587347407.073116}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=188306.521282 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.04742725925\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.09710386341\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.862735003773\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:07.778] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 328, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.09717411773\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.20379104461\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.859396426437\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.99913597106934, \"sum\": 330.99913597106934, \"min\": 330.99913597106934}}, \"EndTime\": 1587347407.779311, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347407.447447}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 721, \"sum\": 721.0, \"min\": 721}, \"Total Records Seen\": {\"count\": 1, \"max\": 706844, \"sum\": 706844.0, \"min\": 706844}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1587347407.779591, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1587347407.448208}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=212902.93776 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=1.04373187321\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=1.08937622316\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:07 INFO 140015383648064] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.859166964679\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:08.100] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 319, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=1.0937371886\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=10, train mse <loss>=1.19626103774\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.856245335545\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 321.6290473937988, \"sum\": 321.6290473937988, \"min\": 321.6290473937988}}, \"EndTime\": 1587347408.101564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347407.779406}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 793, \"sum\": 793.0, \"min\": 793}, \"Total Records Seen\": {\"count\": 1, \"max\": 777429, \"sum\": 777429.0, \"min\": 777429}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1587347408.101802, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1587347407.7799}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=219175.274984 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=1.04000139358\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=1.08160289864\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.855507802675\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:08.411] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 307, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=1.09033243932\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=11, train mse <loss>=1.18882482824\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.853107108703\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.7348213195801, \"sum\": 309.7348213195801, \"min\": 309.7348213195801}}, \"EndTime\": 1587347408.411808, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347408.101637}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 865, \"sum\": 865.0, \"min\": 865}, \"Total Records Seen\": {\"count\": 1, \"max\": 848014, \"sum\": 848014.0, \"min\": 848014}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1587347408.412058, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1587347408.102044}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=227592.242574 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=1.03627472757\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=1.07386531101\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.851802587989\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:08.712] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 298, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=1.08696591082\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=12, train mse <loss>=1.18149489128\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.84999062555\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.9672164916992, \"sum\": 300.9672164916992, \"min\": 300.9672164916992}}, \"EndTime\": 1587347408.713315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347408.411884}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 937, \"sum\": 937.0, \"min\": 937}, \"Total Records Seen\": {\"count\": 1, \"max\": 918599, \"sum\": 918599.0, \"min\": 918599}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1587347408.713637, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1587347408.412313}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=234135.293884 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=1.03257570333\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=1.06621258312\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:08 INFO 140015383648064] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.848078829422\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:09.077] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 361, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=1.08364232678\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=13, train mse <loss>=1.17428069239\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.846899508044\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 363.9400005340576, \"sum\": 363.9400005340576, \"min\": 363.9400005340576}}, \"EndTime\": 1587347409.077911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347408.713401}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1009, \"sum\": 1009.0, \"min\": 1009}, \"Total Records Seen\": {\"count\": 1, \"max\": 989184, \"sum\": 989184.0, \"min\": 989184}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1587347409.078188, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1587347408.713933}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=193698.221735 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=1.02891858368\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=1.05867345184\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.844353535765\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:09.392] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 312, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=1.0803653457\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=14, train mse <loss>=1.16718928019\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.843838864622\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.91708755493164, \"sum\": 314.91708755493164, \"min\": 314.91708755493164}}, \"EndTime\": 1587347409.393469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347409.077998}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1081, \"sum\": 1081.0, \"min\": 1081}, \"Total Records Seen\": {\"count\": 1, \"max\": 1059769, \"sum\": 1059769.0, \"min\": 1059769}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1587347409.39373, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1587347409.078514}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=223808.627612 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=1.02531268043\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=1.05126609265\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.840643101775\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:09.700] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 301, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=1.077137843\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=15, train mse <loss>=1.16022593283\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.840809502912\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.6279888153076, \"sum\": 306.6279888153076, \"min\": 306.6279888153076}}, \"EndTime\": 1587347409.700666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347409.393545}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1153, \"sum\": 1153.0, \"min\": 1153}, \"Total Records Seen\": {\"count\": 1, \"max\": 1130354, \"sum\": 1130354.0, \"min\": 1130354}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1587347409.700938, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1587347409.394001}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=229856.504423 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=1.02176382426\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=1.04400131256\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:09 INFO 140015383648064] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.836976571342\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:10.007] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 304, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=1.07396207848\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=16, train mse <loss>=1.15339454601\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.837814245772\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.5938949584961, \"sum\": 306.5938949584961, \"min\": 306.5938949584961}}, \"EndTime\": 1587347410.007858, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347409.700753}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1225, \"sum\": 1225.0, \"min\": 1225}, \"Total Records Seen\": {\"count\": 1, \"max\": 1200939, \"sum\": 1200939.0, \"min\": 1200939}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1587347410.008187, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1587347409.701227}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=229782.288967 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=1.01827574731\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=1.03688549756\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.833336076026\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:10.323] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 313, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=1.07083973972\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=17, train mse <loss>=1.14669774817\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.83485212439\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.471887588501, \"sum\": 315.471887588501, \"min\": 315.471887588501}}, \"EndTime\": 1587347410.324059, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347410.008006}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1297, \"sum\": 1297.0, \"min\": 1297}, \"Total Records Seen\": {\"count\": 1, \"max\": 1271524, \"sum\": 1271524.0, \"min\": 1271524}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1587347410.324293, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1587347410.008557}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=223467.042344 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=1.01485070992\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=1.02992196342\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.829825449278\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:10.620] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 294, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=1.06777219234\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=18, train mse <loss>=1.14013745474\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.831926172275\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.64015769958496, \"sum\": 296.64015769958496, \"min\": 296.64015769958496}}, \"EndTime\": 1587347410.621245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347410.324125}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1369, \"sum\": 1369.0, \"min\": 1369}, \"Total Records Seen\": {\"count\": 1, \"max\": 1342109, \"sum\": 1342109.0, \"min\": 1342109}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1587347410.621484, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1587347410.324567}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=237614.3992 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=1.01149005059\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=1.02311212244\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.826480734996\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:10.947] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 324, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=1.06476020225\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=19, train mse <loss>=1.13371428829\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.829036282821\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.7941474914551, \"sum\": 326.7941474914551, \"min\": 326.7941474914551}}, \"EndTime\": 1587347410.948564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347410.62133}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1441, \"sum\": 1441.0, \"min\": 1441}, \"Total Records Seen\": {\"count\": 1, \"max\": 1412694, \"sum\": 1412694.0, \"min\": 1412694}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1587347410.94885, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1587347410.621735}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=215683.350981 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=1.00819465672\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=1.01645646585\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:10 INFO 140015383648064] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.823265950685\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:11.266] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 315, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=1.06180445307\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=20, train mse <loss>=1.12742869656\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.826182433004\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.8889751434326, \"sum\": 317.8889751434326, \"min\": 317.8889751434326}}, \"EndTime\": 1587347411.267056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347410.948651}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1513, \"sum\": 1513.0, \"min\": 1513}, \"Total Records Seen\": {\"count\": 1, \"max\": 1483279, \"sum\": 1483279.0, \"min\": 1483279}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1587347411.267321, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1587347410.949129}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=221727.632576 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=1.00496474266\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=1.00995413398\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.820127736635\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:11.599] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 330, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=1.05890521483\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=21, train mse <loss>=1.12128025399\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.823363088586\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 332.40699768066406, \"sum\": 332.40699768066406, \"min\": 332.40699768066406}}, \"EndTime\": 1587347411.600071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347411.267135}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1585, \"sum\": 1585.0, \"min\": 1585}, \"Total Records Seen\": {\"count\": 1, \"max\": 1553864, \"sum\": 1553864.0, \"min\": 1553864}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1587347411.600343, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1587347411.267625}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=212049.744972 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=1.00180005298\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=1.00360334615\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.817099066567\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:11.904] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 302, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=1.05606255441\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=22, train mse <loss>=1.11526811882\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.820583030518\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.8532009124756, \"sum\": 304.8532009124756, \"min\": 304.8532009124756}}, \"EndTime\": 1587347411.905535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347411.600157}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1657, \"sum\": 1657.0, \"min\": 1657}, \"Total Records Seen\": {\"count\": 1, \"max\": 1624449, \"sum\": 1624449.0, \"min\": 1624449}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1587347411.905798, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1587347411.600645}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=231201.7117 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.998700531426\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=0.99740275147\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:11 INFO 140015383648064] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.814226422991\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:12.222] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 314, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=1.05327641049\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=23, train mse <loss>=1.1093911969\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.817844356756\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.39282608032227, \"sum\": 317.39282608032227, \"min\": 317.39282608032227}}, \"EndTime\": 1587347412.22351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347411.905619}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1729, \"sum\": 1729.0, \"min\": 1729}, \"Total Records Seen\": {\"count\": 1, \"max\": 1695034, \"sum\": 1695034.0, \"min\": 1695034}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1587347412.223716, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1587347411.906081}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=222127.39631 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.995665429842\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=0.991349648182\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.811512753277\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:12.590] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 364, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=1.05054639294\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=24, train mse <loss>=1.10364772371\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.815149461186\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 366.9099807739258, \"sum\": 366.9099807739258, \"min\": 366.9099807739258}}, \"EndTime\": 1587347412.590921, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347412.223567}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1801, \"sum\": 1801.0, \"min\": 1801}, \"Total Records Seen\": {\"count\": 1, \"max\": 1765619, \"sum\": 1765619.0, \"min\": 1765619}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1587347412.59115, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1587347412.223978}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=192173.71606 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.992694411277\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=0.985442194181\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.808898802974\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:12.901] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 308, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=1.04787221689\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=25, train mse <loss>=1.09803618293\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.812502807508\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.7421398162842, \"sum\": 310.7421398162842, \"min\": 310.7421398162842}}, \"EndTime\": 1587347412.902161, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347412.590996}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1873, \"sum\": 1873.0, \"min\": 1873}, \"Total Records Seen\": {\"count\": 1, \"max\": 1836204, \"sum\": 1836204.0, \"min\": 1836204}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1587347412.902372, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1587347412.591387}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=226887.06481 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.98978653289\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=0.97967738069\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:12 INFO 140015383648064] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.806359212403\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:13.200] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 296, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=1.04525325517\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=26, train mse <loss>=1.09255436744\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.809906275353\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 298.47192764282227, \"sum\": 298.47192764282227, \"min\": 298.47192764282227}}, \"EndTime\": 1587347413.201176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347412.90223}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1945, \"sum\": 1945.0, \"min\": 1945}, \"Total Records Seen\": {\"count\": 1, \"max\": 1906789, \"sum\": 1906789.0, \"min\": 1906789}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1587347413.201445, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1587347412.902666}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=236128.018121 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.986940890704\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=0.974052321743\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.803894534197\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:13.515] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 311, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=1.04268895705\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=27, train mse <loss>=1.08720026116\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.807363157488\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.0749931335449, \"sum\": 314.0749931335449, \"min\": 314.0749931335449}}, \"EndTime\": 1587347413.515859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347413.201258}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2017, \"sum\": 2017.0, \"min\": 2017}, \"Total Records Seen\": {\"count\": 1, \"max\": 1977374, \"sum\": 1977374.0, \"min\": 1977374}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1587347413.516145, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1587347413.201745}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=224408.496105 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.984156807932\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=0.968564622599\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.801480391136\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:13.830] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 312, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=1.04017856095\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=28, train mse <loss>=1.08197143865\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.804873898236\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.208984375, \"sum\": 314.208984375, \"min\": 314.208984375}}, \"EndTime\": 1587347413.830674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347413.515944}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2089, \"sum\": 2089.0, \"min\": 2089}, \"Total Records Seen\": {\"count\": 1, \"max\": 2047959, \"sum\": 2047959.0, \"min\": 2047959}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1587347413.830911, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1587347413.516431}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=224354.247079 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.981433181766\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=0.963211090272\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:13 INFO 140015383648064] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.799124949895\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:14.134] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 301, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=1.03772130583\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=29, train mse <loss>=1.07686550858\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.802441717873\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.5759925842285, \"sum\": 303.5759925842285, \"min\": 303.5759925842285}}, \"EndTime\": 1587347414.134765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347413.830745}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2161, \"sum\": 2161.0, \"min\": 2161}, \"Total Records Seen\": {\"count\": 1, \"max\": 2118544, \"sum\": 2118544.0, \"min\": 2118544}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1587347414.134978, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1587347413.831157}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=232234.02008 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.978769073989\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=0.957988900198\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.796809912208\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:14.462] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 325, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=1.0353164461\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=30, train mse <loss>=1.07188014357\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.800062580821\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.50606536865234, \"sum\": 327.50606536865234, \"min\": 327.50606536865234}}, \"EndTime\": 1587347414.462747, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347414.134834}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2233, \"sum\": 2233.0, \"min\": 2233}, \"Total Records Seen\": {\"count\": 1, \"max\": 2189129, \"sum\": 2189129.0, \"min\": 2189129}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1587347414.463066, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 30}, \"StartTime\": 1587347414.135208}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=215195.622919 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.976163273527\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=0.952894736584\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.794530549999\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:14.757] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 292, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=1.03296300361\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=31, train mse <loss>=1.06701256684\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.7977380017\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 294.92783546447754, \"sum\": 294.92783546447754, \"min\": 294.92783546447754}}, \"EndTime\": 1587347414.758338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347414.462835}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2305, \"sum\": 2305.0, \"min\": 2305}, \"Total Records Seen\": {\"count\": 1, \"max\": 2259714, \"sum\": 2259714.0, \"min\": 2259714}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1587347414.758607, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 31}, \"StartTime\": 1587347414.463372}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=238966.747685 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.973615113328\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=0.9479263889\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:14 INFO 140015383648064] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.79228446853\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:15.061] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 300, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=1.03066013119\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=32, train mse <loss>=1.06226030602\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.79546811611\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.87981033325195, \"sum\": 302.87981033325195, \"min\": 302.87981033325195}}, \"EndTime\": 1587347415.061811, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347414.758401}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2377, \"sum\": 2377.0, \"min\": 2377}, \"Total Records Seen\": {\"count\": 1, \"max\": 2330299, \"sum\": 2330299.0, \"min\": 2330299}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1587347415.062091, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 32}, \"StartTime\": 1587347414.758894}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=232685.770479 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.971123118625\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.943080111529\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.790062887088\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:15.384] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 320, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=1.0284068728\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=33, train mse <loss>=1.05762069603\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.793253005923\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.894811630249, \"sum\": 322.894811630249, \"min\": 322.894811630249}}, \"EndTime\": 1587347415.385323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347415.061895}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2449, \"sum\": 2449.0, \"min\": 2449}, \"Total Records Seen\": {\"count\": 1, \"max\": 2400884, \"sum\": 2400884.0, \"min\": 2400884}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1587347415.385631, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 33}, \"StartTime\": 1587347415.062391}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=218267.958121 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.968686581894\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.938353693941\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.787875384632\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:15.708] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 321, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=1.02620228419\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=34, train mse <loss>=1.05309112808\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.791092285661\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.591947555542, \"sum\": 323.591947555542, \"min\": 323.591947555542}}, \"EndTime\": 1587347415.709566, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347415.385405}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2521, \"sum\": 2521.0, \"min\": 2521}, \"Total Records Seen\": {\"count\": 1, \"max\": 2471469, \"sum\": 2471469.0, \"min\": 2471469}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1587347415.709887, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 34}, \"StartTime\": 1587347415.385937}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=217771.527862 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.966304175165\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.93374375894\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:15 INFO 140015383648064] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.785718092736\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:16.029] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 317, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=1.02404538467\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=35, train mse <loss>=1.04866894987\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.788983726885\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.02806663513184, \"sum\": 320.02806663513184, \"min\": 320.02806663513184}}, \"EndTime\": 1587347416.030318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347415.709679}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2593, \"sum\": 2593.0, \"min\": 2593}, \"Total Records Seen\": {\"count\": 1, \"max\": 2542054, \"sum\": 2542054.0, \"min\": 2542054}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1587347416.030593, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 35}, \"StartTime\": 1587347415.710254}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=220224.414516 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.963974898412\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.929247604769\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.783591072804\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:16.344] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 312, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=1.02193518228\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=36, train mse <loss>=1.04435151678\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.786928596045\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.5740032196045, \"sum\": 314.5740032196045, \"min\": 314.5740032196045}}, \"EndTime\": 1587347416.345462, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347416.030403}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2665, \"sum\": 2665.0, \"min\": 2665}, \"Total Records Seen\": {\"count\": 1, \"max\": 2612639, \"sum\": 2612639.0, \"min\": 2612639}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1587347416.345735, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 36}, \"StartTime\": 1587347416.03085}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=224056.599997 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.961697605308\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.924862284056\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.781505807305\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:16.658] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 310, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=1.01987066113\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=37, train mse <loss>=1.04013616544\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.784924549569\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.70813941955566, \"sum\": 312.70813941955566, \"min\": 312.70813941955566}}, \"EndTime\": 1587347416.658778, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347416.34555}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2737, \"sum\": 2737.0, \"min\": 2737}, \"Total Records Seen\": {\"count\": 1, \"max\": 2683224, \"sum\": 2683224.0, \"min\": 2683224}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1587347416.659041, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 37}, \"StartTime\": 1587347416.346032}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=225406.816407 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.959471194063\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.920584972236\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.779470585721\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:16.983] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 322, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=1.01785083191\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=38, train mse <loss>=1.03602031603\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.782968683582\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.21915435791016, \"sum\": 325.21915435791016, \"min\": 325.21915435791016}}, \"EndTime\": 1587347416.984564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347416.658858}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2809, \"sum\": 2809.0, \"min\": 2809}, \"Total Records Seen\": {\"count\": 1, \"max\": 2753809, \"sum\": 2753809.0, \"min\": 2753809}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1587347416.984823, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 38}, \"StartTime\": 1587347416.65931}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=216758.428647 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.957294640617\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.916413028955\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:16 INFO 140015383648064] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.777468276456\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:17.300] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 314, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=1.01587471203\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=39, train mse <loss>=1.03200143055\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.781060746498\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 316.47205352783203, \"sum\": 316.47205352783203, \"min\": 316.47205352783203}}, \"EndTime\": 1587347417.301597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347416.984645}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2881, \"sum\": 2881.0, \"min\": 2881}, \"Total Records Seen\": {\"count\": 1, \"max\": 2824394, \"sum\": 2824394.0, \"min\": 2824394}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1587347417.301875, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 39}, \"StartTime\": 1587347416.98509}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=222712.745486 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.955166775095\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.912343568245\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.775489239146\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:17.703] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 399, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=1.01394127311\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=40, train mse <loss>=1.02807690531\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.779200040705\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 401.561975479126, \"sum\": 401.561975479126, \"min\": 401.561975479126}}, \"EndTime\": 1587347417.703779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347417.301681}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2953, \"sum\": 2953.0, \"min\": 2953}, \"Total Records Seen\": {\"count\": 1, \"max\": 2894979, \"sum\": 2894979.0, \"min\": 2894979}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1587347417.704015, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 40}, \"StartTime\": 1587347417.302178}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=175590.222294 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.953086570652\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.908374011157\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:17 INFO 140015383648064] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.773568351024\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:18.031] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 325, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=1.01204952523\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=41, train mse <loss>=1.02424424152\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.777385377362\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.3739814758301, \"sum\": 327.3739814758301, \"min\": 327.3739814758301}}, \"EndTime\": 1587347418.031724, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347417.703849}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3025, \"sum\": 3025.0, \"min\": 3025}, \"Total Records Seen\": {\"count\": 1, \"max\": 2965564, \"sum\": 2965564.0, \"min\": 2965564}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1587347418.032037, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 41}, \"StartTime\": 1587347417.704314}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=215276.992499 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.951052822782\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.904501471721\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.771682033117\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:18.347] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 313, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=1.01019845699\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=42, train mse <loss>=1.02050092251\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.775611147421\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.60206413269043, \"sum\": 315.60206413269043, \"min\": 315.60206413269043}}, \"EndTime\": 1587347418.347969, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347418.03181}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3097, \"sum\": 3097.0, \"min\": 3097}, \"Total Records Seen\": {\"count\": 1, \"max\": 3036149, \"sum\": 3036149.0, \"min\": 3036149}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1587347418.348416, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 42}, \"StartTime\": 1587347418.032338}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=223216.164968 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.94906450381\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.900723432391\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.769824145066\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:18.657] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 307, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=1.00838707159\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=43, train mse <loss>=1.01684448614\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.773877390114\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.5560073852539, \"sum\": 309.5560073852539, \"min\": 309.5560073852539}}, \"EndTime\": 1587347418.658262, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347418.348099}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3169, \"sum\": 3169.0, \"min\": 3169}, \"Total Records Seen\": {\"count\": 1, \"max\": 3106734, \"sum\": 3106734.0, \"min\": 3106734}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1587347418.658553, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 43}, \"StartTime\": 1587347418.348668}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=227671.527762 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.94712060321\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.897037437024\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.768024897431\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:18.984] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 324, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=1.00661444076\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=44, train mse <loss>=1.01327263235\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.772180994325\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.59006118774414, \"sum\": 326.59006118774414, \"min\": 326.59006118774414}}, \"EndTime\": 1587347418.985475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347418.658352}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3241, \"sum\": 3241.0, \"min\": 3241}, \"Total Records Seen\": {\"count\": 1, \"max\": 3177319, \"sum\": 3177319.0, \"min\": 3177319}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1587347418.985737, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 44}, \"StartTime\": 1587347418.658848}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=215835.8755 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.945219900899\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.893440661056\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:18 INFO 140015383648064] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.766302404269\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:19.292] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 304, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=1.00487955684\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=45, train mse <loss>=1.00978292375\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.770522208228\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.9159984588623, \"sum\": 306.9159984588623, \"min\": 306.9159984588623}}, \"EndTime\": 1587347419.293026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347418.985563}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3313, \"sum\": 3313.0, \"min\": 3313}, \"Total Records Seen\": {\"count\": 1, \"max\": 3247904, \"sum\": 3247904.0, \"min\": 3247904}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1587347419.293247, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 45}, \"StartTime\": 1587347418.986079}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=229695.467801 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.943361551456\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.889931016765\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.764638981349\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:19.591] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 296, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=1.00318144163\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=46, train mse <loss>=1.00637300484\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.76890139939\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 298.19703102111816, \"sum\": 298.19703102111816, \"min\": 298.19703102111816}}, \"EndTime\": 1587347419.591717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347419.293099}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3385, \"sum\": 3385.0, \"min\": 3385}, \"Total Records Seen\": {\"count\": 1, \"max\": 3318489, \"sum\": 3318489.0, \"min\": 3318489}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1587347419.591992, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 46}, \"StartTime\": 1587347419.293484}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=236349.137717 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.941544305694\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.886505679585\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.763007181271\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:19.886] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 292, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=1.0015191722\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=47, train mse <loss>=1.00304065229\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.767316305262\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 294.8579788208008, \"sum\": 294.8579788208008, \"min\": 294.8579788208008}}, \"EndTime\": 1587347419.887167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347419.591802}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3457, \"sum\": 3457.0, \"min\": 3457}, \"Total Records Seen\": {\"count\": 1, \"max\": 3389074, \"sum\": 3389074.0, \"min\": 3389074}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1587347419.887384, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 47}, \"StartTime\": 1587347419.59228}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=239051.455028 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.939767127952\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.883162254779\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:19 INFO 140015383648064] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.761410995268\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:20.194] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 305, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.999891843262\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.999783698222\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.765768376501\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.4958324432373, \"sum\": 307.4958324432373, \"min\": 307.4958324432373}}, \"EndTime\": 1587347420.195197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347419.887241}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3529, \"sum\": 3529.0, \"min\": 3529}, \"Total Records Seen\": {\"count\": 1, \"max\": 3459659, \"sum\": 3459659.0, \"min\": 3459659}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1587347420.195401, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 48}, \"StartTime\": 1587347419.887673}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=229288.978157 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.938029165872\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.879898716027\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.75985865142\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:20.496] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 299, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.998298453177\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.996599801616\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.764254776605\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.43213272094727, \"sum\": 301.43213272094727, \"min\": 301.43213272094727}}, \"EndTime\": 1587347420.497141, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347420.195261}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3601, \"sum\": 3601.0, \"min\": 3601}, \"Total Records Seen\": {\"count\": 1, \"max\": 3530244, \"sum\": 3530244.0, \"min\": 3530244}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1587347420.497416, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 49}, \"StartTime\": 1587347420.195671}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=233798.775975 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=0.936329260666\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=50, batch=0 train mse <loss>=0.876712484379\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=50, batch=0 train absolute_loss <loss>=0.758329763739\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:20.797] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 298, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=0.996738141395\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=50, train mse <loss>=0.993486922512\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=50, train absolute_loss <loss>=0.762773843412\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.45604705810547, \"sum\": 300.45604705810547, \"min\": 300.45604705810547}}, \"EndTime\": 1587347420.798191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347420.497227}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3673, \"sum\": 3673.0, \"min\": 3673}, \"Total Records Seen\": {\"count\": 1, \"max\": 3600829, \"sum\": 3600829.0, \"min\": 3600829}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 52, \"sum\": 52.0, \"min\": 52}}, \"EndTime\": 1587347420.798449, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 50}, \"StartTime\": 1587347420.497695}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=234560.83691 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=0.934666503152\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=51, batch=0 train mse <loss>=0.873601472114\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:20 INFO 140015383648064] #quality_metric: host=algo-1, epoch=51, batch=0 train absolute_loss <loss>=0.756821323449\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:21.099] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 299, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=0.995210040322\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=51, train mse <loss>=0.990443024357\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=51, train absolute_loss <loss>=0.761323466174\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.4681339263916, \"sum\": 301.4681339263916, \"min\": 301.4681339263916}}, \"EndTime\": 1587347421.100432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347420.798277}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3745, \"sum\": 3745.0, \"min\": 3745}, \"Total Records Seen\": {\"count\": 1, \"max\": 3671414, \"sum\": 3671414.0, \"min\": 3671414}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 53, \"sum\": 53.0, \"min\": 53}}, \"EndTime\": 1587347421.100648, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 51}, \"StartTime\": 1587347420.798938}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=233853.625196 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=0.933039940253\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=52, batch=0 train mse <loss>=0.870563530106\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=52, batch=0 train absolute_loss <loss>=0.755330813003\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:21.415] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 313, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=0.993713241225\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=52, train mse <loss>=0.987466005785\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=52, train absolute_loss <loss>=0.759905110902\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.5210018157959, \"sum\": 315.5210018157959, \"min\": 315.5210018157959}}, \"EndTime\": 1587347421.416432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347421.100484}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3817, \"sum\": 3817.0, \"min\": 3817}, \"Total Records Seen\": {\"count\": 1, \"max\": 3741999, \"sum\": 3741999.0, \"min\": 3741999}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 54, \"sum\": 54.0, \"min\": 54}}, \"EndTime\": 1587347421.416641, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 52}, \"StartTime\": 1587347421.100881}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=223452.36845 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=0.931448476093\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=53, batch=0 train mse <loss>=0.867596263617\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=53, batch=0 train absolute_loss <loss>=0.753858478017\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:21.726] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 308, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=0.992246890041\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=53, train mse <loss>=0.984553890795\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=53, train absolute_loss <loss>=0.758516433173\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.3599548339844, \"sum\": 310.3599548339844, \"min\": 310.3599548339844}}, \"EndTime\": 1587347421.727261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347421.416495}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3889, \"sum\": 3889.0, \"min\": 3889}, \"Total Records Seen\": {\"count\": 1, \"max\": 3812584, \"sum\": 3812584.0, \"min\": 3812584}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}}, \"EndTime\": 1587347421.727527, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 53}, \"StartTime\": 1587347421.416867}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=227116.991749 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=0.929891168322\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=54, batch=0 train mse <loss>=0.864697584924\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:21 INFO 140015383648064] #quality_metric: host=algo-1, epoch=54, batch=0 train absolute_loss <loss>=0.752420406226\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:22.029] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 300, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=0.990810129524\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=54, train mse <loss>=0.981704712767\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=54, train absolute_loss <loss>=0.757157235985\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.63805389404297, \"sum\": 302.63805389404297, \"min\": 302.63805389404297}}, \"EndTime\": 1587347422.030445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347421.727345}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3961, \"sum\": 3961.0, \"min\": 3961}, \"Total Records Seen\": {\"count\": 1, \"max\": 3883169, \"sum\": 3883169.0, \"min\": 3883169}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 56, \"sum\": 56.0, \"min\": 56}}, \"EndTime\": 1587347422.03065, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 54}, \"StartTime\": 1587347421.727781}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=232982.231194 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=0.928367262847\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=55, batch=0 train mse <loss>=0.861865774726\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=55, batch=0 train absolute_loss <loss>=0.751012790611\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:22.351] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 319, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=0.989402172319\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=55, train mse <loss>=0.978916658589\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=55, train absolute_loss <loss>=0.755826113876\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 321.7151165008545, \"sum\": 321.7151165008545, \"min\": 321.7151165008545}}, \"EndTime\": 1587347422.352595, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347422.030523}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4033, \"sum\": 4033.0, \"min\": 4033}, \"Total Records Seen\": {\"count\": 1, \"max\": 3953754, \"sum\": 3953754.0, \"min\": 3953754}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 57, \"sum\": 57.0, \"min\": 57}}, \"EndTime\": 1587347422.352854, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 55}, \"StartTime\": 1587347422.030844}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=219112.822782 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=0.926875698836\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=56, batch=0 train mse <loss>=0.859098561093\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=56, batch=0 train absolute_loss <loss>=0.749631885552\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:22.679] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 325, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=0.988022201142\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=56, train mse <loss>=0.97618786995\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=56, train absolute_loss <loss>=0.754522183318\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.2709846496582, \"sum\": 327.2709846496582, \"min\": 327.2709846496582}}, \"EndTime\": 1587347422.680458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347422.352674}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4105, \"sum\": 4105.0, \"min\": 4105}, \"Total Records Seen\": {\"count\": 1, \"max\": 4024339, \"sum\": 4024339.0, \"min\": 4024339}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 58, \"sum\": 58.0, \"min\": 58}}, \"EndTime\": 1587347422.680732, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 56}, \"StartTime\": 1587347422.35315}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=215376.754133 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=0.925415571032\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=57, batch=0 train mse <loss>=0.856393979109\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:22 INFO 140015383648064] #quality_metric: host=algo-1, epoch=57, batch=0 train absolute_loss <loss>=0.748267620862\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:23.020] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 337, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=0.986669402947\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=57, train mse <loss>=0.973516510712\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=57, train absolute_loss <loss>=0.753243752302\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 340.11197090148926, \"sum\": 340.11197090148926, \"min\": 340.11197090148926}}, \"EndTime\": 1587347423.021178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347422.680543}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4177, \"sum\": 4177.0, \"min\": 4177}, \"Total Records Seen\": {\"count\": 1, \"max\": 4094924, \"sum\": 4094924.0, \"min\": 4094924}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 59, \"sum\": 59.0, \"min\": 59}}, \"EndTime\": 1587347423.021447, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 57}, \"StartTime\": 1587347422.681028}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=207226.340747 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=0.923986098096\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=58, batch=0 train mse <loss>=0.853750309474\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=58, batch=0 train absolute_loss <loss>=0.746931540414\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:23.322] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 299, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=0.98534302717\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=58, train mse <loss>=0.970900881192\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=58, train absolute_loss <loss>=0.751992271486\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.3348579406738, \"sum\": 301.3348579406738, \"min\": 301.3348579406738}}, \"EndTime\": 1587347423.323172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347423.02126}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4249, \"sum\": 4249.0, \"min\": 4249}, \"Total Records Seen\": {\"count\": 1, \"max\": 4165509, \"sum\": 4165509.0, \"min\": 4165509}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 60, \"sum\": 60.0, \"min\": 60}}, \"EndTime\": 1587347423.323402, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 58}, \"StartTime\": 1587347423.021801}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=233917.186435 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=0.922586157956\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=59, batch=0 train mse <loss>=0.851165218852\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=59, batch=0 train absolute_loss <loss>=0.745646424936\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:23.650] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 324, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=0.984042281495\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=59, train mse <loss>=0.968339211771\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=59, train absolute_loss <loss>=0.750767317017\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.470064163208, \"sum\": 327.470064163208, \"min\": 327.470064163208}}, \"EndTime\": 1587347423.651218, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347423.323246}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4321, \"sum\": 4321.0, \"min\": 4321}, \"Total Records Seen\": {\"count\": 1, \"max\": 4236094, \"sum\": 4236094.0, \"min\": 4236094}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 61, \"sum\": 61.0, \"min\": 61}}, \"EndTime\": 1587347423.6515, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 59}, \"StartTime\": 1587347423.323707}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=215238.334277 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=0.921215185377\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=60, batch=0 train mse <loss>=0.848637417768\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=60, batch=0 train absolute_loss <loss>=0.744384151589\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:23.976] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 322, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=0.982766483652\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=60, train mse <loss>=0.96582996139\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=60, train absolute_loss <loss>=0.749567928608\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.3211975097656, \"sum\": 325.3211975097656, \"min\": 325.3211975097656}}, \"EndTime\": 1587347423.977163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347423.651306}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4393, \"sum\": 4393.0, \"min\": 4393}, \"Total Records Seen\": {\"count\": 1, \"max\": 4306679, \"sum\": 4306679.0, \"min\": 4306679}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 62, \"sum\": 62.0, \"min\": 62}}, \"EndTime\": 1587347423.977418, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 60}, \"StartTime\": 1587347423.651807}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=216687.829703 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=0.919872308592\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=61, batch=0 train mse <loss>=0.846165064115\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:23 INFO 140015383648064] #quality_metric: host=algo-1, epoch=61, batch=0 train absolute_loss <loss>=0.743137351944\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:24.277] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 298, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=0.981514932415\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=61, train mse <loss>=0.963371562553\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=61, train absolute_loss <loss>=0.748390707745\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.56309700012207, \"sum\": 300.56309700012207, \"min\": 300.56309700012207}}, \"EndTime\": 1587347424.278266, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347423.977265}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4465, \"sum\": 4465.0, \"min\": 4465}, \"Total Records Seen\": {\"count\": 1, \"max\": 4377264, \"sum\": 4377264.0, \"min\": 4377264}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 63, \"sum\": 63.0, \"min\": 63}}, \"EndTime\": 1587347424.27857, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 61}, \"StartTime\": 1587347423.977665}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=234472.039124 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=0.918556480989\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=62, batch=0 train mse <loss>=0.843746008767\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=62, batch=0 train absolute_loss <loss>=0.741915850572\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:24.585] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 305, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=0.980286798475\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=62, train mse <loss>=0.960962207265\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=62, train absolute_loss <loss>=0.747236947312\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.33418464660645, \"sum\": 307.33418464660645, \"min\": 307.33418464660645}}, \"EndTime\": 1587347424.58623, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347424.278359}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4537, \"sum\": 4537.0, \"min\": 4537}, \"Total Records Seen\": {\"count\": 1, \"max\": 4447849, \"sum\": 4447849.0, \"min\": 4447849}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 64, \"sum\": 64.0, \"min\": 64}}, \"EndTime\": 1587347424.586517, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 62}, \"StartTime\": 1587347424.27886}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=229324.677293 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=0.917267417323\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=63, batch=0 train mse <loss>=0.841379514882\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=63, batch=0 train absolute_loss <loss>=0.74071356852\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:24.882] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 294, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=0.979081552383\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=63, train mse <loss>=0.958600686216\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=63, train absolute_loss <loss>=0.746107050697\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.1709499359131, \"sum\": 296.1709499359131, \"min\": 296.1709499359131}}, \"EndTime\": 1587347424.882992, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347424.586316}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4609, \"sum\": 4609.0, \"min\": 4609}, \"Total Records Seen\": {\"count\": 1, \"max\": 4518434, \"sum\": 4518434.0, \"min\": 4518434}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 65, \"sum\": 65.0, \"min\": 65}}, \"EndTime\": 1587347424.883217, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 63}, \"StartTime\": 1587347424.586788}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=238010.208293 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=0.916003856385\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=64, batch=0 train mse <loss>=0.839063064913\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:24 INFO 140015383648064] #quality_metric: host=algo-1, epoch=64, batch=0 train absolute_loss <loss>=0.73953842685\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:25.203] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 318, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=0.977898479919\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=64, train mse <loss>=0.956285437028\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=64, train absolute_loss <loss>=0.744999951866\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.45984268188477, \"sum\": 320.45984268188477, \"min\": 320.45984268188477}}, \"EndTime\": 1587347425.203951, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347424.88307}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4681, \"sum\": 4681.0, \"min\": 4681}, \"Total Records Seen\": {\"count\": 1, \"max\": 4589019, \"sum\": 4589019.0, \"min\": 4589019}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 66, \"sum\": 66.0, \"min\": 66}}, \"EndTime\": 1587347425.204211, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 64}, \"StartTime\": 1587347424.883456}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=219968.992982 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=0.914765165483\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=65, batch=0 train mse <loss>=0.836795307981\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=65, batch=0 train absolute_loss <loss>=0.738390486965\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:25.505] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 299, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=0.976736919926\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=65, train mse <loss>=0.954015010746\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=65, train absolute_loss <loss>=0.743913970749\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.81884765625, \"sum\": 301.81884765625, \"min\": 301.81884765625}}, \"EndTime\": 1587347425.506334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347425.20402}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4753, \"sum\": 4753.0, \"min\": 4753}, \"Total Records Seen\": {\"count\": 1, \"max\": 4659604, \"sum\": 4659604.0, \"min\": 4659604}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 67, \"sum\": 67.0, \"min\": 67}}, \"EndTime\": 1587347425.506626, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 65}, \"StartTime\": 1587347425.204479}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=233497.840814 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=0.913550908066\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=66, batch=0 train mse <loss>=0.834575261628\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=66, batch=0 train absolute_loss <loss>=0.737263362892\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:25.817] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 309, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=0.975596225874\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=66, train mse <loss>=0.95178799594\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=66, train absolute_loss <loss>=0.742848255372\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.4738464355469, \"sum\": 311.4738464355469, \"min\": 311.4738464355469}}, \"EndTime\": 1587347425.818425, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347425.506413}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4825, \"sum\": 4825.0, \"min\": 4825}, \"Total Records Seen\": {\"count\": 1, \"max\": 4730189, \"sum\": 4730189.0, \"min\": 4730189}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}}, \"EndTime\": 1587347425.818645, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 66}, \"StartTime\": 1587347425.506921}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=226327.514514 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=0.912359970257\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=67, batch=0 train mse <loss>=0.832400715327\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:25 INFO 140015383648064] #quality_metric: host=algo-1, epoch=67, batch=0 train absolute_loss <loss>=0.736176887988\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:26.111] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 290, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=0.974475854924\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=67, train mse <loss>=0.94960319183\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=67, train absolute_loss <loss>=0.741803471791\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.62495040893555, \"sum\": 292.62495040893555, \"min\": 292.62495040893555}}, \"EndTime\": 1587347426.111559, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347425.818514}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4897, \"sum\": 4897.0, \"min\": 4897}, \"Total Records Seen\": {\"count\": 1, \"max\": 4800774, \"sum\": 4800774.0, \"min\": 4800774}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 69, \"sum\": 69.0, \"min\": 69}}, \"EndTime\": 1587347426.111823, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 67}, \"StartTime\": 1587347425.818902}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=240852.71079 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=0.911191971775\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=68, batch=0 train mse <loss>=0.830270809427\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=68, batch=0 train absolute_loss <loss>=0.735118904344\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:26.407] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 293, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=0.973375192975\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=68, train mse <loss>=0.947459266299\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=68, train absolute_loss <loss>=0.740776344298\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.5141067504883, \"sum\": 295.5141067504883, \"min\": 295.5141067504883}}, \"EndTime\": 1587347426.407661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347426.111641}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4969, \"sum\": 4969.0, \"min\": 4969}, \"Total Records Seen\": {\"count\": 1, \"max\": 4871359, \"sum\": 4871359.0, \"min\": 4871359}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 70, \"sum\": 70.0, \"min\": 70}}, \"EndTime\": 1587347426.407948, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 68}, \"StartTime\": 1587347426.112112}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=238469.173382 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=0.910046123795\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=69, batch=0 train mse <loss>=0.828183947435\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=69, batch=0 train absolute_loss <loss>=0.734095552318\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:26.712] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 302, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=0.9722936592\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=69, train mse <loss>=0.945354959721\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=69, train absolute_loss <loss>=0.739767941484\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.86202239990234, \"sum\": 304.86202239990234, \"min\": 304.86202239990234}}, \"EndTime\": 1587347426.713171, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347426.407747}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5041, \"sum\": 5041.0, \"min\": 5041}, \"Total Records Seen\": {\"count\": 1, \"max\": 4941944, \"sum\": 4941944.0, \"min\": 4941944}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 71, \"sum\": 71.0, \"min\": 71}}, \"EndTime\": 1587347426.713431, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 69}, \"StartTime\": 1587347426.408272}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=231194.309177 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=0.908921699413\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=70, batch=0 train mse <loss>=0.826138655664\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:26 INFO 140015383648064] #quality_metric: host=algo-1, epoch=70, batch=0 train absolute_loss <loss>=0.73309602488\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:27.021] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 306, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=0.971230675618\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=70, train mse <loss>=0.943289025262\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=70, train absolute_loss <loss>=0.738779125559\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 308.73990058898926, \"sum\": 308.73990058898926, \"min\": 308.73990058898926}}, \"EndTime\": 1587347427.022503, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347426.713249}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5113, \"sum\": 5113.0, \"min\": 5113}, \"Total Records Seen\": {\"count\": 1, \"max\": 5012529, \"sum\": 5012529.0, \"min\": 5012529}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}}, \"EndTime\": 1587347427.022712, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 70}, \"StartTime\": 1587347426.713732}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=228347.776868 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=0.907818338584\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=71, batch=0 train mse <loss>=0.82413413587\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=71, batch=0 train absolute_loss <loss>=0.732118541326\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:27.325] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 300, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=0.970185783254\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=71, train mse <loss>=0.941260454027\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=71, train absolute_loss <loss>=0.737809390796\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.12108993530273, \"sum\": 303.12108993530273, \"min\": 303.12108993530273}}, \"EndTime\": 1587347427.3261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347427.022568}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5185, \"sum\": 5185.0, \"min\": 5185}, \"Total Records Seen\": {\"count\": 1, \"max\": 5083114, \"sum\": 5083114.0, \"min\": 5083114}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 73, \"sum\": 73.0, \"min\": 73}}, \"EndTime\": 1587347427.32635, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 71}, \"StartTime\": 1587347427.022944}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=232548.690931 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=0.906735068551\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=72, batch=0 train mse <loss>=0.82216848454\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=72, batch=0 train absolute_loss <loss>=0.731167645522\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:27.632] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 304, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=0.969158411884\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=72, train mse <loss>=0.939268027326\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=72, train absolute_loss <loss>=0.736858349158\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.5969944000244, \"sum\": 306.5969944000244, \"min\": 306.5969944000244}}, \"EndTime\": 1587347427.633298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347427.326178}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5257, \"sum\": 5257.0, \"min\": 5257}, \"Total Records Seen\": {\"count\": 1, \"max\": 5153699, \"sum\": 5153699.0, \"min\": 5153699}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 74, \"sum\": 74.0, \"min\": 74}}, \"EndTime\": 1587347427.633569, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 72}, \"StartTime\": 1587347427.326666}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=229879.706585 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=0.90567162241\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=73, batch=0 train mse <loss>=0.820241087639\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=73, batch=0 train absolute_loss <loss>=0.730239898866\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:27.965] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 329, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=0.96814807026\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=73, train mse <loss>=0.937310685947\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=73, train absolute_loss <loss>=0.735924464703\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.9079875946045, \"sum\": 331.9079875946045, \"min\": 331.9079875946045}}, \"EndTime\": 1587347427.96581, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347427.633377}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5329, \"sum\": 5329.0, \"min\": 5329}, \"Total Records Seen\": {\"count\": 1, \"max\": 5224284, \"sum\": 5224284.0, \"min\": 5224284}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 75, \"sum\": 75.0, \"min\": 75}}, \"EndTime\": 1587347427.966079, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 73}, \"StartTime\": 1587347427.633863}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=212372.679194 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=0.904627357364\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=74, batch=0 train mse <loss>=0.818350655692\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:27 INFO 140015383648064] #quality_metric: host=algo-1, epoch=74, batch=0 train absolute_loss <loss>=0.729328239947\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:28.260] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 292, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=0.967154241231\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=74, train mse <loss>=0.935387326332\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=74, train absolute_loss <loss>=0.735005896176\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 294.27194595336914, \"sum\": 294.27194595336914, \"min\": 294.27194595336914}}, \"EndTime\": 1587347428.260675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347427.965894}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5401, \"sum\": 5401.0, \"min\": 5401}, \"Total Records Seen\": {\"count\": 1, \"max\": 5294869, \"sum\": 5294869.0, \"min\": 5294869}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 76, \"sum\": 76.0, \"min\": 76}}, \"EndTime\": 1587347428.260925, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 74}, \"StartTime\": 1587347427.966369}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=239516.386304 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=0.903601558441\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=75, batch=0 train mse <loss>=0.816495776416\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=75, batch=0 train absolute_loss <loss>=0.728433282802\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:28.570] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 308, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=0.966176504403\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=75, train mse <loss>=0.933497037659\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=75, train absolute_loss <loss>=0.734102000546\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.1379871368408, \"sum\": 310.1379871368408, \"min\": 310.1379871368408}}, \"EndTime\": 1587347428.571524, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347428.260753}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5473, \"sum\": 5473.0, \"min\": 5473}, \"Total Records Seen\": {\"count\": 1, \"max\": 5365454, \"sum\": 5365454.0, \"min\": 5365454}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 77, \"sum\": 77.0, \"min\": 77}}, \"EndTime\": 1587347428.571788, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 75}, \"StartTime\": 1587347428.261354}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=227273.559587 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=0.902593914434\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=76, batch=0 train mse <loss>=0.814675774373\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=76, batch=0 train absolute_loss <loss>=0.727555518659\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:28.886] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 312, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=0.965214387374\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=76, train mse <loss>=0.931638813594\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=76, train absolute_loss <loss>=0.733213909515\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.79406356811523, \"sum\": 314.79406356811523, \"min\": 314.79406356811523}}, \"EndTime\": 1587347428.886924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347428.571606}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5545, \"sum\": 5545.0, \"min\": 5545}, \"Total Records Seen\": {\"count\": 1, \"max\": 5436039, \"sum\": 5436039.0, \"min\": 5436039}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 78, \"sum\": 78.0, \"min\": 78}}, \"EndTime\": 1587347428.887156, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 76}, \"StartTime\": 1587347428.572096}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=223942.200232 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=0.901603771114\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=77, batch=0 train mse <loss>=0.812889360086\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:28 INFO 140015383648064] #quality_metric: host=algo-1, epoch=77, batch=0 train absolute_loss <loss>=0.726686043998\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:29.185] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 296, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=0.964267452234\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=77, train mse <loss>=0.929811719438\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=77, train absolute_loss <loss>=0.732342386363\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 298.68292808532715, \"sum\": 298.68292808532715, \"min\": 298.68292808532715}}, \"EndTime\": 1587347429.186114, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347428.887005}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5617, \"sum\": 5617.0, \"min\": 5617}, \"Total Records Seen\": {\"count\": 1, \"max\": 5506624, \"sum\": 5506624.0, \"min\": 5506624}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 79, \"sum\": 79.0, \"min\": 79}}, \"EndTime\": 1587347429.186368, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 77}, \"StartTime\": 1587347428.8874}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=235963.719214 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=0.900630674862\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=78, batch=0 train mse <loss>=0.811135612503\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=78, batch=0 train absolute_loss <loss>=0.725832964093\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:29.481] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 293, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=0.963335296682\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=78, train mse <loss>=0.928014893833\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=78, train absolute_loss <loss>=0.731483775019\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.5589294433594, \"sum\": 295.5589294433594, \"min\": 295.5589294433594}}, \"EndTime\": 1587347429.482349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347429.186195}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5689, \"sum\": 5689.0, \"min\": 5689}, \"Total Records Seen\": {\"count\": 1, \"max\": 5577209, \"sum\": 5577209.0, \"min\": 5577209}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 80, \"sum\": 80.0, \"min\": 80}}, \"EndTime\": 1587347429.482898, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 78}, \"StartTime\": 1587347429.186687}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=238147.482331 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=0.899674169113\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=79, batch=0 train mse <loss>=0.80941361057\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=79, batch=0 train absolute_loss <loss>=0.724988173671\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:29.792] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 307, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=0.96241750066\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=79, train mse <loss>=0.926247445577\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=79, train absolute_loss <loss>=0.730638344123\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.8728656768799, \"sum\": 309.8728656768799, \"min\": 309.8728656768799}}, \"EndTime\": 1587347429.793316, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347429.482459}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5761, \"sum\": 5761.0, \"min\": 5761}, \"Total Records Seen\": {\"count\": 1, \"max\": 5647794, \"sum\": 5647794.0, \"min\": 5647794}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 81, \"sum\": 81.0, \"min\": 81}}, \"EndTime\": 1587347429.793594, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 79}, \"StartTime\": 1587347429.483408}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=227454.980601 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=0.898733828581\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=80, batch=0 train mse <loss>=0.807722494636\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:29 INFO 140015383648064] #quality_metric: host=algo-1, epoch=80, batch=0 train absolute_loss <loss>=0.7241511201\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:30.098] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 303, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=0.961513645398\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=80, train mse <loss>=0.924508490286\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=80, train absolute_loss <loss>=0.729806566142\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.6490421295166, \"sum\": 305.6490421295166, \"min\": 305.6490421295166}}, \"EndTime\": 1587347430.099531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347429.793392}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5833, \"sum\": 5833.0, \"min\": 5833}, \"Total Records Seen\": {\"count\": 1, \"max\": 5718379, \"sum\": 5718379.0, \"min\": 5718379}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 82, \"sum\": 82.0, \"min\": 82}}, \"EndTime\": 1587347430.09994, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 80}, \"StartTime\": 1587347429.793848}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=230487.661732 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=0.897809122721\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=81, batch=0 train mse <loss>=0.806061220841\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=81, batch=0 train absolute_loss <loss>=0.723321741975\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:30.397] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 296, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=0.960623383615\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=81, train mse <loss>=0.922797285149\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=81, train absolute_loss <loss>=0.7289881315\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 298.2778549194336, \"sum\": 298.2778549194336, \"min\": 298.2778549194336}}, \"EndTime\": 1587347430.39856, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347430.099617}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5905, \"sum\": 5905.0, \"min\": 5905}, \"Total Records Seen\": {\"count\": 1, \"max\": 5788964, \"sum\": 5788964.0, \"min\": 5788964}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 83, \"sum\": 83.0, \"min\": 83}}, \"EndTime\": 1587347430.398816, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 81}, \"StartTime\": 1587347430.100244}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=236297.072328 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=0.896899586426\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=82, batch=0 train mse <loss>=0.804428868131\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=82, batch=0 train absolute_loss <loss>=0.72250126737\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:30.690] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 289, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=0.959746333723\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=82, train mse <loss>=0.921113025095\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=82, train absolute_loss <loss>=0.72818328837\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 291.70894622802734, \"sum\": 291.70894622802734, \"min\": 291.70894622802734}}, \"EndTime\": 1587347430.690822, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347430.398646}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5977, \"sum\": 5977.0, \"min\": 5977}, \"Total Records Seen\": {\"count\": 1, \"max\": 5859549, \"sum\": 5859549.0, \"min\": 5859549}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 84, \"sum\": 84.0, \"min\": 84}}, \"EndTime\": 1587347430.691076, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 82}, \"StartTime\": 1587347430.399081}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=241595.464593 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=83, batch=0 train rmse <loss>=0.896004957505\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=83, batch=0 train mse <loss>=0.802824883874\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:30 INFO 140015383648064] #quality_metric: host=algo-1, epoch=83, batch=0 train absolute_loss <loss>=0.72169393313\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:31.013] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 168, \"duration\": 320, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=83, train rmse <loss>=0.958882136192\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=83, train mse <loss>=0.919454951108\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=83, train absolute_loss <loss>=0.727391658948\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.282075881958, \"sum\": 322.282075881958, \"min\": 322.282075881958}}, \"EndTime\": 1587347431.013689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347430.690891}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6049, \"sum\": 6049.0, \"min\": 6049}, \"Total Records Seen\": {\"count\": 1, \"max\": 5930134, \"sum\": 5930134.0, \"min\": 5930134}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 85, \"sum\": 85.0, \"min\": 85}}, \"EndTime\": 1587347431.013899, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 83}, \"StartTime\": 1587347430.691376}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=218769.081725 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=84, batch=0 train rmse <loss>=0.895124697575\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=84, batch=0 train mse <loss>=0.801248224209\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=84, batch=0 train absolute_loss <loss>=0.720897712938\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:31.309] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 170, \"duration\": 293, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=84, train rmse <loss>=0.958030447918\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=84, train mse <loss>=0.917822339139\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=84, train absolute_loss <loss>=0.72661299762\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.504093170166, \"sum\": 295.504093170166, \"min\": 295.504093170166}}, \"EndTime\": 1587347431.309664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347431.013753}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6121, \"sum\": 6121.0, \"min\": 6121}, \"Total Records Seen\": {\"count\": 1, \"max\": 6000719, \"sum\": 6000719.0, \"min\": 6000719}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 86, \"sum\": 86.0, \"min\": 86}}, \"EndTime\": 1587347431.309921, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 84}, \"StartTime\": 1587347431.014127}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=238505.675011 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=85, batch=0 train rmse <loss>=0.894258505746\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=85, batch=0 train mse <loss>=0.7996982751\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=85, batch=0 train absolute_loss <loss>=0.720110519071\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:31.626] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 172, \"duration\": 313, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=85, train rmse <loss>=0.957190950806\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=85, train mse <loss>=0.916214516305\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=85, train absolute_loss <loss>=0.725846605069\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 316.4050579071045, \"sum\": 316.4050579071045, \"min\": 316.4050579071045}}, \"EndTime\": 1587347431.626673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347431.309737}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6193, \"sum\": 6193.0, \"min\": 6193}, \"Total Records Seen\": {\"count\": 1, \"max\": 6071304, \"sum\": 6071304.0, \"min\": 6071304}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 87, \"sum\": 87.0, \"min\": 87}}, \"EndTime\": 1587347431.626953, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 85}, \"StartTime\": 1587347431.310229}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=222754.973504 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=86, batch=0 train rmse <loss>=0.89340601056\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=86, batch=0 train mse <loss>=0.798174299704\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=86, batch=0 train absolute_loss <loss>=0.719336342764\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:31.939] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 174, \"duration\": 310, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=86, train rmse <loss>=0.956363355487\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=86, train mse <loss>=0.914630867719\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=86, train absolute_loss <loss>=0.725092054026\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.58296966552734, \"sum\": 312.58296966552734, \"min\": 312.58296966552734}}, \"EndTime\": 1587347431.939873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347431.626762}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6265, \"sum\": 6265.0, \"min\": 6265}, \"Total Records Seen\": {\"count\": 1, \"max\": 6141889, \"sum\": 6141889.0, \"min\": 6141889}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 88, \"sum\": 88.0, \"min\": 88}}, \"EndTime\": 1587347431.940138, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 86}, \"StartTime\": 1587347431.627252}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=225489.566447 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=87, batch=0 train rmse <loss>=0.892566735303\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=87, batch=0 train mse <loss>=0.796675376969\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:31 INFO 140015383648064] #quality_metric: host=algo-1, epoch=87, batch=0 train absolute_loss <loss>=0.718577087525\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:32.268] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 176, \"duration\": 326, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=87, train rmse <loss>=0.955547255561\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=87, train mse <loss>=0.913070557609\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=87, train absolute_loss <loss>=0.724349057944\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 328.4258842468262, \"sum\": 328.4258842468262, \"min\": 328.4258842468262}}, \"EndTime\": 1587347432.268899, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347431.93996}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6337, \"sum\": 6337.0, \"min\": 6337}, \"Total Records Seen\": {\"count\": 1, \"max\": 6212474, \"sum\": 6212474.0, \"min\": 6212474}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 89, \"sum\": 89.0, \"min\": 89}}, \"EndTime\": 1587347432.269162, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 87}, \"StartTime\": 1587347431.940434}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=214634.755706 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=88, batch=0 train rmse <loss>=0.891740476298\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=88, batch=0 train mse <loss>=0.795201077068\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=88, batch=0 train absolute_loss <loss>=0.717824525277\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:32.575] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 178, \"duration\": 304, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=88, train rmse <loss>=0.954742484882\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=88, train mse <loss>=0.911533212438\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=88, train absolute_loss <loss>=0.723618025325\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.8809509277344, \"sum\": 306.8809509277344, \"min\": 306.8809509277344}}, \"EndTime\": 1587347432.576345, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347432.268981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6409, \"sum\": 6409.0, \"min\": 6409}, \"Total Records Seen\": {\"count\": 1, \"max\": 6283059, \"sum\": 6283059.0, \"min\": 6283059}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 90, \"sum\": 90.0, \"min\": 90}}, \"EndTime\": 1587347432.576562, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 88}, \"StartTime\": 1587347432.269434}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=229681.390059 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=89, batch=0 train rmse <loss>=0.890926718392\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=89, batch=0 train mse <loss>=0.793750417544\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=89, batch=0 train absolute_loss <loss>=0.71708504199\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:32.876] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 180, \"duration\": 298, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=89, train rmse <loss>=0.953948638087\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=89, train mse <loss>=0.910018004109\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=89, train absolute_loss <loss>=0.722897979682\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.609827041626, \"sum\": 300.609827041626, \"min\": 300.609827041626}}, \"EndTime\": 1587347432.87751, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347432.576413}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6481, \"sum\": 6481.0, \"min\": 6481}, \"Total Records Seen\": {\"count\": 1, \"max\": 6353644, \"sum\": 6353644.0, \"min\": 6353644}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}}, \"EndTime\": 1587347432.877777, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 89}, \"StartTime\": 1587347432.576864}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=234465.168459 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=90, batch=0 train rmse <loss>=0.890125392396\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=90, batch=0 train mse <loss>=0.792323214187\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:32 INFO 140015383648064] #quality_metric: host=algo-1, epoch=90, batch=0 train absolute_loss <loss>=0.716365085041\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:33.254] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 182, \"duration\": 375, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, epoch=90, train rmse <loss>=0.953165545184\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, epoch=90, train mse <loss>=0.908524556526\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, epoch=90, train absolute_loss <loss>=0.72218869928\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, train rmse <loss>=0.953165545184\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, train mse <loss>=0.908524556526\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, train absolute_loss <loss>=0.72218869928\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 377.63500213623047, \"sum\": 377.63500213623047, \"min\": 377.63500213623047}}, \"EndTime\": 1587347433.255755, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347432.877592}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6553, \"sum\": 6553.0, \"min\": 6553}, \"Total Records Seen\": {\"count\": 1, \"max\": 6424229, \"sum\": 6424229.0, \"min\": 6424229}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 92, \"sum\": 92.0, \"min\": 92}}, \"EndTime\": 1587347433.256014, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 90}, \"StartTime\": 1587347432.878081}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #throughput_metric: host=algo-1, train throughput=186691.344767 records/second\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 WARNING 140015383648064] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 3.239870071411133, \"sum\": 3.239870071411133, \"min\": 3.239870071411133}}, \"EndTime\": 1587347433.259616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347433.255843}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] Saved checkpoint to \"/tmp/tmprSYY56/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:33.266] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 29137, \"num_examples\": 1, \"num_bytes\": 63616}\u001b[0m\n",
      "\u001b[34m[2020-04-20 01:50:33.373] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 107, \"num_examples\": 31, \"num_bytes\": 1936064}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30251, \"sum\": 30251.0, \"min\": 30251}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Total Records Seen\": {\"count\": 1, \"max\": 30251, \"sum\": 30251.0, \"min\": 30251}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30251, \"sum\": 30251.0, \"min\": 30251}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587347433.37349, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347433.266051}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #test_score (algo-1) : ('rmse', 0.9026666789823493)\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #test_score (algo-1) : ('mse', 0.8148071333450237)\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #test_score (algo-1) : ('absolute_loss', 0.7177793299721109)\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, test rmse <loss>=0.902666678982\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, test mse <loss>=0.814807133345\u001b[0m\n",
      "\u001b[34m[04/20/2020 01:50:33 INFO 140015383648064] #quality_metric: host=algo-1, test absolute_loss <loss>=0.717779329972\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 29304.367780685425, \"sum\": 29304.367780685425, \"min\": 29304.367780685425}, \"setuptime\": {\"count\": 1, \"max\": 47.93095588684082, \"sum\": 47.93095588684082, \"min\": 47.93095588684082}}, \"EndTime\": 1587347433.374263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1587347433.259672}\n",
      "\u001b[0m\n",
      "\n",
      "2020-04-20 01:50:45 Uploading - Uploading generated training model\n",
      "2020-04-20 01:50:45 Completed - Training job completed\n",
      "Training seconds: 94\n",
      "Billable seconds: 94\n"
     ]
    }
   ],
   "source": [
    "# New Hyperparameters\n",
    "# Reference: Supported channels by algorithm\n",
    "#   https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
    "estimator.fit({'train':s3_training_file_location, 'test': s3_test_file_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# Ref: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.m4.xlarge',\n",
    "                             endpoint_name = 'fm-movie-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Predictions\n",
    "\n",
    "### Dense and Sparse Formats\n",
    "\n",
    "Ref: [Common Data Formats for Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.predictor import json_deserializer\n",
    "\n",
    "def fm_sparse_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        \n",
    "        column_list = row.tolist()\n",
    "        value_list = np.ones(len(column_list),dtype=int).tolist()\n",
    "       \n",
    "        js['instances'].append({'data':{'features': { 'keys': column_list, 'shape':[dim_movie], 'values': value_list}}})\n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.content_type = 'application/json'\n",
    "predictor.serializer = fm_sparse_serializer\n",
    "predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"data\": {\"features\": {\"keys\": [341, 1416], \"shape\": [10334], \"values\": [1, 1]}}}]}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_sparse_serializer([np.array([341,1416])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '561:1', '2822:1']\n",
      "***Actual Rating: 4\n",
      "***Predicted Rating: {'predictions': [{'score': 3.306558609008789}]}\n",
      "['3.5', '473:1', '2600:1']\n",
      "***Actual Rating: 3.5\n",
      "***Predicted Rating: {'predictions': [{'score': 3.339083433151245}]}\n",
      "['4.5', '361:1', '2548:1']\n",
      "***Actual Rating: 4.5\n",
      "***Predicted Rating: {'predictions': [{'score': 4.247658729553223}]}\n"
     ]
    }
   ],
   "source": [
    "# Let's test with few entries from test file\n",
    "# Movie dataset is updated regularly...so, instead of hard coding userid and movie id, let's\n",
    "# use actual values\n",
    "\n",
    "# Each row is in this format: ['2.5', '426:1', '943:1']\n",
    "# ActualRating, UserID, MovieID\n",
    "\n",
    "with open(r'ml-latest-small/user_movie_test.svm','r') as f:\n",
    "    for i in range(3):\n",
    "        rating = f.readline().split()\n",
    "        print(rating)\n",
    "        print ('***Actual Rating:',rating[0])\n",
    "        # UserID, MovieID\n",
    "        userID = rating[1].split(':')[0]\n",
    "        movieID = rating[2].split(':')[0]\n",
    "        predicted_rating = predictor.predict([np.array([int(userID),int(movieID)])])\n",
    "        print('***Predicted Rating:', predicted_rating)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
