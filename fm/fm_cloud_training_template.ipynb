{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization Machine - Cloud Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define IAM Role for AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "# SageMaker SDK Documentation: http://sagemaker.readthedocs.io/en/latest/estimators.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your bucket name\n",
    "bucket_name = 's3-2-ml-sagemaker'\n",
    "training_file_key = 'movie/user_movie_train.recordio'\n",
    "test_file_key = 'movie/user_movie_test.recordio'\n",
    "\n",
    "s3_model_output_location = r's3://{0}/movie/model'.format(bucket_name)\n",
    "s3_training_file_location = r's3://{0}/{1}'.format(bucket_name,training_file_key)\n",
    "s3_test_file_location = r's3://{0}/{1}'.format(bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dimensions\n",
    "\n",
    "Number of unique users + Number of unique movies in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_movie = 0\n",
    "\n",
    "# Update movie dimension - from training file\n",
    "with open(r'ml-latest-small/movie_dimension.txt','r') as f:\n",
    "    dim_movie = int(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_movie # data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://s3-2-ml-sagemaker/movie/model\n",
      "s3://s3-2-ml-sagemaker/movie/user_movie_train.recordio\n",
      "s3://s3-2-ml-sagemaker/movie/user_movie_test.recordio\n"
     ]
    }
   ],
   "source": [
    "print(s3_model_output_location)\n",
    "print(s3_training_file_location)\n",
    "print(s3_test_file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing and reading from S3 Bucket\n",
    "\n",
    "Ref: [Boto3 Read Docs](http://boto3.readthedocs.io/en/latest/guide/s3.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f: # read as binary mode\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3(r'ml-latest-small/user_movie_train.recordio',bucket_name,training_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3(r'ml-latest-small/user_movie_test.recordio',bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Algorithm Docker Image\n",
    "\n",
    "### AWS Maintains a separate image for every region and algorithm\n",
    "\n",
    "This allows quick deployment machines ready for the task.\n",
    "\n",
    "Registry Path for algorithms by SageMaker\n",
    "[Latest Dockers](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Algorithms that are parallelizable can be deployed on multiple compute instances for distributed training. For the Training Image and Inference Image Registry Path column, use the :1 version tag to ensure that you are using a stable version of the algorithm. You can reliably host a model trained using an image with the :1 tag on an inference image that has the :1 tag. Using the :latest tag in the registry path provides you with the most up-to-date version of the algorithm, but might cause problems with backward compatibility. Avoid using the :latest tag for production purposes.\" - [AWS SageMaker Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html)\n",
    "\n",
    "- First run will be using only one Docker.\n",
    "- Next run will allow more, say a six-pack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us-east-2 : 404615174143.dkr.ecr.us-east-2.amazonaws.com\n",
    "# us-east-1 : 382416733822.dkr.ecr.us-east-1.amazonaws.com\n",
    "\n",
    "containers = {'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/factorization-machines:latest',\n",
    "             'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:latest',\n",
    "             'us-west-1': '632365934929.dkr.ecr.us-west-1.amazonaws.com/factorization-machines:latest',\n",
    "             'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/factorization-machines:latest',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::399426528351:role/service-role/AmazonSageMaker-ExecutionRole-20200203T173955\n"
     ]
    }
   ],
   "source": [
    "# This role contains the permissions needed to train, deploy models\n",
    "# SageMaker Service is trusted to assume this role\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access appropriate algorithm container image\n",
    "#  Specify how many instances to use for distributed training and what type of machine to use\n",
    "#  Finally, specify where the trained model artifacts needs to be stored\n",
    "#   Reference: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "#    Optionally, give a name to the training job using base_job_name\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.m4.xlarge',\n",
    "                                       output_path=s3_model_output_location,\n",
    "                                       sagemaker_session=sess,\n",
    "                                       base_job_name ='fm-movie-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nestimator.set_hyperparameters(feature_dim=dim_movie,\\n                              num_factors=8,\\n                              predictor_type='regressor', \\n                              mini_batch_size=1000,\\n                              epochs=100)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This was the original set of hyperparameters that was used. TEST RMSE was 0.89\n",
    "# Movie lens dataset was updated recently and these parameters are no longer sufficient to produce\n",
    "# quality predictions. With new dataset, TEST RMSE is around 1.9\n",
    "# Refer to next cell for new settings\n",
    "'''\n",
    "estimator.set_hyperparameters(feature_dim=dim_movie,\n",
    "                              num_factors=8,\n",
    "                              predictor_type='regressor', \n",
    "                              mini_batch_size=1000,\n",
    "                              epochs=100)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Configuration after Model Tuning\n",
    "# Refer to Hyperparameter Tuning Section on how to optimize hyperparameters\n",
    "estimator.set_hyperparameters(feature_dim=dim_movie,\n",
    "                              num_factors=8,\n",
    "                              predictor_type='regressor', \n",
    "                              mini_batch_size=994,\n",
    "                              epochs=91,\n",
    "                              bias_init_method='normal',\n",
    "                              bias_lr=0.21899531189430518,\n",
    "                              factors_init_method='normal',\n",
    "                              factors_lr=5.357593337770278e-05,\n",
    "                              linear_init_method='normal',\n",
    "                              linear_lr=0.00021524948053767607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 10334,\n",
       " 'num_factors': 8,\n",
       " 'predictor_type': 'regressor',\n",
       " 'mini_batch_size': 994,\n",
       " 'epochs': 91,\n",
       " 'bias_init_method': 'normal',\n",
       " 'bias_lr': 0.21899531189430518,\n",
       " 'factors_init_method': 'normal',\n",
       " 'factors_lr': 5.357593337770278e-05,\n",
       " 'linear_init_method': 'normal',\n",
       " 'linear_lr': 0.00021524948053767607}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 21:10:45 Starting - Starting the training job...\n",
      "2020-05-07 21:10:46 Starting - Launching requested ML instances......\n",
      "2020-05-07 21:11:47 Starting - Preparing the instances for training...\n",
      "2020-05-07 21:12:40 Downloading - Downloading input data...\n",
      "2020-05-07 21:13:14 Training - Downloading the training image...\n",
      "2020-05-07 21:13:33 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:35 INFO 139783205549888] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:35 INFO 139783205549888] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'predictor_type': u'regressor', u'factors_lr': u'5.357593337770278e-05', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'epochs': u'91', u'linear_lr': u'0.00021524948053767607', u'feature_dim': u'10334', u'bias_lr': u'0.21899531189430518', u'factors_init_method': u'normal', u'num_factors': u'8', u'mini_batch_size': u'994'}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:35 INFO 139783205549888] Final configuration: {u'factors_lr': u'5.357593337770278e-05', u'linear_init_sigma': u'0.01', u'epochs': u'91', u'feature_dim': u'10334', u'num_factors': u'8', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.00021524948053767607', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.21899531189430518', u'mini_batch_size': u'994', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:35 WARNING 139783205549888] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:35 INFO 139783205549888] Using default worker.\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:35.995] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:36.001] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 9, \"num_examples\": 1, \"num_bytes\": 63616}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] nvidia-smi took: 0.0251331329346 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 36.84115409851074, \"sum\": 36.84115409851074, \"min\": 36.84115409851074}}, \"EndTime\": 1588886016.03657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886015.990527}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 994, \"sum\": 994.0, \"min\": 994}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 994, \"sum\": 994.0, \"min\": 994}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588886016.036818, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886016.036756}\n",
      "\u001b[0m\n",
      "\u001b[34m[21:13:36] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202841.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[21:13:36] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202841.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.69335891676\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=13.640900088\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.54139780087\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:36.388] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 327, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.52218752747\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=0, train mse <loss>=2.31705486878\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.15293863895\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"update.time\": {\"count\": 1, \"max\": 352.1599769592285, \"sum\": 352.1599769592285, \"min\": 352.1599769592285}}, \"EndTime\": 1588886016.389215, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886016.036681}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 73, \"sum\": 73.0, \"min\": 73}, \"Total Records Seen\": {\"count\": 1, \"max\": 71579, \"sum\": 71579.0, \"min\": 71579}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1588886016.38946, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1588886016.037023}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=200208.250863 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.05502593497\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.11307972346\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.855960224236\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:36.731] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 340, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.11829382809\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.25058108594\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.880092219168\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 342.53787994384766, \"sum\": 342.53787994384766, \"min\": 342.53787994384766}}, \"EndTime\": 1588886016.732276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886016.389308}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 145, \"sum\": 145.0, \"min\": 145}, \"Total Records Seen\": {\"count\": 1, \"max\": 142164, \"sum\": 142164.0, \"min\": 142164}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1588886016.732564, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1588886016.3897}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=205782.347596 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.05901082426\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.1215039259\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:36 INFO 139783205549888] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.86679396447\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:37.089] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 354, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.11910035629\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.25238560745\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.8800459149\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 357.5739860534668, \"sum\": 357.5739860534668, \"min\": 357.5739860534668}}, \"EndTime\": 1588886017.090499, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886016.732369}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 217, \"sum\": 217.0, \"min\": 217}, \"Total Records Seen\": {\"count\": 1, \"max\": 212749, \"sum\": 212749.0, \"min\": 212749}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1588886017.09107, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1588886016.732887}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=196968.41229 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.05973361329\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.12303533113\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.870267933283\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:37.448] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 354, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.1170214062\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.2477368219\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.877613571648\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 357.52296447753906, \"sum\": 357.52296447753906, \"min\": 357.52296447753906}}, \"EndTime\": 1588886017.449177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886017.090668}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 289, \"sum\": 289.0, \"min\": 289}, \"Total Records Seen\": {\"count\": 1, \"max\": 283334, \"sum\": 283334.0, \"min\": 283334}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1588886017.449399, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1588886017.09162}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=197143.775601 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.06039644162\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.12444061341\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.872994129327\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:37.813] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 362, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.11419897822\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.24143936307\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.87483129964\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 364.3231391906738, \"sum\": 364.3231391906738, \"min\": 364.3231391906738}}, \"EndTime\": 1588886017.813989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886017.449255}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 361, \"sum\": 361.0, \"min\": 361}, \"Total Records Seen\": {\"count\": 1, \"max\": 353919, \"sum\": 353919.0, \"min\": 353919}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1588886017.814254, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1588886017.44963}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=193494.401364 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.0595209431\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.12258462887\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:37 INFO 139783205549888] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.873270875252\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:38.177] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 360, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.11096970839\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.23425369297\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.871875722004\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 363.89780044555664, \"sum\": 363.89780044555664, \"min\": 363.89780044555664}}, \"EndTime\": 1588886018.178507, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886017.814072}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 433, \"sum\": 433.0, \"min\": 433}, \"Total Records Seen\": {\"count\": 1, \"max\": 424504, \"sum\": 424504.0, \"min\": 424504}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1588886018.178811, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1588886017.814569}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=193699.869238 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.05734996075\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.1179889395\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.871761759522\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:38.561] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 380, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.10756806146\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.22670701076\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.868818565793\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 383.3789825439453, \"sum\": 383.3789825439453, \"min\": 383.3789825439453}}, \"EndTime\": 1588886018.562556, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886018.178604}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 505, \"sum\": 505.0, \"min\": 505}, \"Total Records Seen\": {\"count\": 1, \"max\": 495089, \"sum\": 495089.0, \"min\": 495089}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1588886018.562843, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1588886018.179136}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=183852.401275 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.05439758432\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.11175426583\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.869227940888\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:38.992] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 426, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.10410710668\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.21905250302\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.86569912077\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 429.81600761413574, \"sum\": 429.81600761413574, \"min\": 429.81600761413574}}, \"EndTime\": 1588886018.993119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886018.562647}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 577, \"sum\": 577.0, \"min\": 577}, \"Total Records Seen\": {\"count\": 1, \"max\": 565674, \"sum\": 565674.0, \"min\": 565674}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1588886018.993399, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1588886018.563265}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:38 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=164040.991466 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.05102114671\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.10464545083\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.866134551449\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:39.401] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 405, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.10063494662\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.21139728573\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.862549616138\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 408.83493423461914, \"sum\": 408.83493423461914, \"min\": 408.83493423461914}}, \"EndTime\": 1588886019.402639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886018.993211}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 649, \"sum\": 649.0, \"min\": 649}, \"Total Records Seen\": {\"count\": 1, \"max\": 636259, \"sum\": 636259.0, \"min\": 636259}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1588886019.403007, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1588886018.993704}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=172314.014177 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.04742725925\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.09710386341\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.862735003773\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:39.739] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 333, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.09717411773\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.20379104461\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.859396426437\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 336.38691902160645, \"sum\": 336.38691902160645, \"min\": 336.38691902160645}}, \"EndTime\": 1588886019.73993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886019.402743}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 721, \"sum\": 721.0, \"min\": 721}, \"Total Records Seen\": {\"count\": 1, \"max\": 706844, \"sum\": 706844.0, \"min\": 706844}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1588886019.740214, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1588886019.403503}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=209535.602296 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=1.04373187321\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=1.08937622316\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:39 INFO 139783205549888] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.859166964679\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:40.059] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 317, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=1.0937371886\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=10, train mse <loss>=1.19626103774\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.856245335545\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.019006729126, \"sum\": 320.019006729126, \"min\": 320.019006729126}}, \"EndTime\": 1588886020.060596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886019.740022}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 793, \"sum\": 793.0, \"min\": 793}, \"Total Records Seen\": {\"count\": 1, \"max\": 777429, \"sum\": 777429.0, \"min\": 777429}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1588886020.060879, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1588886019.740539}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=220233.424812 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=1.04000139358\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=1.08160289864\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.855507802675\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:40.384] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 322, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=1.09033243932\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=11, train mse <loss>=1.18882482824\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.853107108703\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.3091106414795, \"sum\": 324.3091106414795, \"min\": 324.3091106414795}}, \"EndTime\": 1588886020.385518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886020.060695}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 865, \"sum\": 865.0, \"min\": 865}, \"Total Records Seen\": {\"count\": 1, \"max\": 848014, \"sum\": 848014.0, \"min\": 848014}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1588886020.385749, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1588886020.061172}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=217383.125272 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=1.03627472757\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=1.07386531101\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.851802587989\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:40.677] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 290, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=1.08696591082\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=12, train mse <loss>=1.18149489128\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.84999062555\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.5398349761963, \"sum\": 292.5398349761963, \"min\": 292.5398349761963}}, \"EndTime\": 1588886020.678565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886020.385597}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 937, \"sum\": 937.0, \"min\": 937}, \"Total Records Seen\": {\"count\": 1, \"max\": 918599, \"sum\": 918599.0, \"min\": 918599}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1588886020.678851, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1588886020.385989}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=240895.43404 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=1.03257570333\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=1.06621258312\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:40 INFO 139783205549888] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.848078829422\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:41.009] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 328, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=1.08364232678\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=13, train mse <loss>=1.17428069239\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.846899508044\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.40110969543457, \"sum\": 331.40110969543457, \"min\": 331.40110969543457}}, \"EndTime\": 1588886021.010603, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886020.678655}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1009, \"sum\": 1009.0, \"min\": 1009}, \"Total Records Seen\": {\"count\": 1, \"max\": 989184, \"sum\": 989184.0, \"min\": 989184}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1588886021.010883, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1588886020.679164}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=212686.819198 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=1.02891858368\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=1.05867345184\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.844353535765\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:41.337] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 324, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=1.0803653457\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=14, train mse <loss>=1.16718928019\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.843838864622\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.5540599822998, \"sum\": 326.5540599822998, \"min\": 326.5540599822998}}, \"EndTime\": 1588886021.337786, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886021.010689}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1081, \"sum\": 1081.0, \"min\": 1081}, \"Total Records Seen\": {\"count\": 1, \"max\": 1059769, \"sum\": 1059769.0, \"min\": 1059769}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1588886021.338012, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1588886021.011198}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=215885.925348 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=1.02531268043\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=1.05126609265\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.840643101775\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:41.637] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 297, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=1.077137843\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=15, train mse <loss>=1.16022593283\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.840809502912\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.0218868255615, \"sum\": 300.0218868255615, \"min\": 300.0218868255615}}, \"EndTime\": 1588886021.638335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886021.337859}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1153, \"sum\": 1153.0, \"min\": 1153}, \"Total Records Seen\": {\"count\": 1, \"max\": 1130354, \"sum\": 1130354.0, \"min\": 1130354}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1588886021.638624, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1588886021.338253}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=234839.555696 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=1.02176382426\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=1.04400131256\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.836976571342\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:41.942] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 301, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=1.07396207848\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=16, train mse <loss>=1.15339454601\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.837814245772\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.87091636657715, \"sum\": 303.87091636657715, \"min\": 303.87091636657715}}, \"EndTime\": 1588886021.942902, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886021.63843}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1225, \"sum\": 1225.0, \"min\": 1225}, \"Total Records Seen\": {\"count\": 1, \"max\": 1200939, \"sum\": 1200939.0, \"min\": 1200939}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1588886021.943186, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1588886021.638993}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=231920.381344 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=1.01827574731\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=1.03688549756\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:41 INFO 139783205549888] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.833336076026\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:42.263] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 318, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=1.07083973972\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=17, train mse <loss>=1.14669774817\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.83485212439\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.73497772216797, \"sum\": 320.73497772216797, \"min\": 320.73497772216797}}, \"EndTime\": 1588886022.264276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886021.942991}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1297, \"sum\": 1297.0, \"min\": 1297}, \"Total Records Seen\": {\"count\": 1, \"max\": 1271524, \"sum\": 1271524.0, \"min\": 1271524}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1588886022.264659, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1588886021.943503}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=219677.481182 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=1.01485070992\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=1.02992196342\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.829825449278\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:42.581] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 314, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=1.06777219234\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=18, train mse <loss>=1.14013745474\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.831926172275\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.5549507141113, \"sum\": 317.5549507141113, \"min\": 317.5549507141113}}, \"EndTime\": 1588886022.582625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886022.264414}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1369, \"sum\": 1369.0, \"min\": 1369}, \"Total Records Seen\": {\"count\": 1, \"max\": 1342109, \"sum\": 1342109.0, \"min\": 1342109}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1588886022.582906, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1588886022.265031}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=221943.7221 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=1.01149005059\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=1.02311212244\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.826480734996\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:42.913] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 328, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=1.06476020225\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=19, train mse <loss>=1.13371428829\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.829036282821\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.3990364074707, \"sum\": 330.3990364074707, \"min\": 330.3990364074707}}, \"EndTime\": 1588886022.913647, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886022.582709}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1441, \"sum\": 1441.0, \"min\": 1441}, \"Total Records Seen\": {\"count\": 1, \"max\": 1412694, \"sum\": 1412694.0, \"min\": 1412694}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1588886022.913871, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1588886022.583215}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=213385.700074 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=1.00819465672\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=1.01645646585\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:42 INFO 139783205549888] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.823265950685\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:43.218] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 303, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=1.06180445307\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=20, train mse <loss>=1.12742869656\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.826182433004\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.3739070892334, \"sum\": 305.3739070892334, \"min\": 305.3739070892334}}, \"EndTime\": 1588886023.219514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886022.913719}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1513, \"sum\": 1513.0, \"min\": 1513}, \"Total Records Seen\": {\"count\": 1, \"max\": 1483279, \"sum\": 1483279.0, \"min\": 1483279}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1588886023.219782, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1588886022.914104}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=230805.711568 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=1.00496474266\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=1.00995413398\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.820127736635\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:43.536] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 314, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=1.05890521483\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=21, train mse <loss>=1.12128025399\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.823363088586\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.14701652526855, \"sum\": 317.14701652526855, \"min\": 317.14701652526855}}, \"EndTime\": 1588886023.53727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886023.219592}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1585, \"sum\": 1585.0, \"min\": 1585}, \"Total Records Seen\": {\"count\": 1, \"max\": 1553864, \"sum\": 1553864.0, \"min\": 1553864}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1588886023.537503, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1588886023.220089}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=222280.662724 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=1.00180005298\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=1.00360334615\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.817099066567\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:43.833] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 294, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=1.05606255441\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=22, train mse <loss>=1.11526811882\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.820583030518\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.3089942932129, \"sum\": 296.3089942932129, \"min\": 296.3089942932129}}, \"EndTime\": 1588886023.834091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886023.537351}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1657, \"sum\": 1657.0, \"min\": 1657}, \"Total Records Seen\": {\"count\": 1, \"max\": 1624449, \"sum\": 1624449.0, \"min\": 1624449}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1588886023.83438, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1588886023.537745}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=237843.471677 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.998700531426\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=0.99740275147\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:43 INFO 139783205549888] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.814226422991\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:44.189] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 353, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=1.05327641049\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=23, train mse <loss>=1.1093911969\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.817844356756\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 355.1979064941406, \"sum\": 355.1979064941406, \"min\": 355.1979064941406}}, \"EndTime\": 1588886024.189908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886023.834177}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1729, \"sum\": 1729.0, \"min\": 1729}, \"Total Records Seen\": {\"count\": 1, \"max\": 1695034, \"sum\": 1695034.0, \"min\": 1695034}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1588886024.190186, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1588886023.834671}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=198458.044532 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.995665429842\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=0.991349648182\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.811512753277\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:44.494] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 302, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=1.05054639294\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=24, train mse <loss>=1.10364772371\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.815149461186\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.60190773010254, \"sum\": 304.60190773010254, \"min\": 304.60190773010254}}, \"EndTime\": 1588886024.495135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886024.189995}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1801, \"sum\": 1801.0, \"min\": 1801}, \"Total Records Seen\": {\"count\": 1, \"max\": 1765619, \"sum\": 1765619.0, \"min\": 1765619}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1588886024.495383, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1588886024.190495}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=231398.865293 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.992694411277\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=0.985442194181\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.808898802974\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:44.799] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 302, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=1.04787221689\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=25, train mse <loss>=1.09803618293\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.812502807508\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.49604988098145, \"sum\": 304.49604988098145, \"min\": 304.49604988098145}}, \"EndTime\": 1588886024.800207, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886024.495225}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1873, \"sum\": 1873.0, \"min\": 1873}, \"Total Records Seen\": {\"count\": 1, \"max\": 1836204, \"sum\": 1836204.0, \"min\": 1836204}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1588886024.800473, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1588886024.495674}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=231471.052208 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.98978653289\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=0.97967738069\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:44 INFO 139783205549888] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.806359212403\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:45.135] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 333, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=1.04525325517\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=26, train mse <loss>=1.09255436744\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.809906275353\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.54887771606445, \"sum\": 335.54887771606445, \"min\": 335.54887771606445}}, \"EndTime\": 1588886025.136302, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886024.800283}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1945, \"sum\": 1945.0, \"min\": 1945}, \"Total Records Seen\": {\"count\": 1, \"max\": 1906789, \"sum\": 1906789.0, \"min\": 1906789}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1588886025.136535, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1588886024.800719}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=210113.190133 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.986940890704\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=0.974052321743\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.803894534197\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:45.449] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 311, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=1.04268895705\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=27, train mse <loss>=1.08720026116\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.807363157488\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.60602378845215, \"sum\": 313.60602378845215, \"min\": 313.60602378845215}}, \"EndTime\": 1588886025.450419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886025.136382}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2017, \"sum\": 2017.0, \"min\": 2017}, \"Total Records Seen\": {\"count\": 1, \"max\": 1977374, \"sum\": 1977374.0, \"min\": 1977374}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1588886025.450712, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1588886025.136775}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=224726.5243 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.984156807932\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=0.968564622599\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.801480391136\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:45.776] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 323, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=1.04017856095\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=28, train mse <loss>=1.08197143865\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.804873898236\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.66213607788086, \"sum\": 325.66213607788086, \"min\": 325.66213607788086}}, \"EndTime\": 1588886025.776732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886025.450514}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2089, \"sum\": 2089.0, \"min\": 2089}, \"Total Records Seen\": {\"count\": 1, \"max\": 2047959, \"sum\": 2047959.0, \"min\": 2047959}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1588886025.776978, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1588886025.451033}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=216451.460147 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.981433181766\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=0.963211090272\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:45 INFO 139783205549888] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.799124949895\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:46.125] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 346, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=1.03772130583\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=29, train mse <loss>=1.07686550858\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.802441717873\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 348.53386878967285, \"sum\": 348.53386878967285, \"min\": 348.53386878967285}}, \"EndTime\": 1588886026.125844, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886025.776821}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2161, \"sum\": 2161.0, \"min\": 2161}, \"Total Records Seen\": {\"count\": 1, \"max\": 2118544, \"sum\": 2118544.0, \"min\": 2118544}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1588886026.12614, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1588886025.777279}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=202254.547382 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.978769073989\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=0.957988900198\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.796809912208\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:46.426] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 298, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=1.0353164461\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=30, train mse <loss>=1.07188014357\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.800062580821\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.7640838623047, \"sum\": 300.7640838623047, \"min\": 300.7640838623047}}, \"EndTime\": 1588886026.427226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886026.125969}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2233, \"sum\": 2233.0, \"min\": 2233}, \"Total Records Seen\": {\"count\": 1, \"max\": 2189129, \"sum\": 2189129.0, \"min\": 2189129}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1588886026.427506, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 30}, \"StartTime\": 1588886026.126425}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=234332.847478 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.976163273527\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=0.952894736584\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.794530549999\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:46.719] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 290, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=1.03296300361\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=31, train mse <loss>=1.06701256684\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.7977380017\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.38390922546387, \"sum\": 292.38390922546387, \"min\": 292.38390922546387}}, \"EndTime\": 1588886026.720202, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886026.427316}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2305, \"sum\": 2305.0, \"min\": 2305}, \"Total Records Seen\": {\"count\": 1, \"max\": 2259714, \"sum\": 2259714.0, \"min\": 2259714}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1588886026.720428, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 31}, \"StartTime\": 1588886026.427789}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=241081.201469 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.973615113328\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=0.9479263889\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:46 INFO 139783205549888] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.79228446853\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:47.046] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 324, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=1.03066013119\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=32, train mse <loss>=1.06226030602\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.79546811611\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.5950679779053, \"sum\": 326.5950679779053, \"min\": 326.5950679779053}}, \"EndTime\": 1588886027.047335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886026.720271}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2377, \"sum\": 2377.0, \"min\": 2377}, \"Total Records Seen\": {\"count\": 1, \"max\": 2330299, \"sum\": 2330299.0, \"min\": 2330299}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1588886027.04762, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 32}, \"StartTime\": 1588886026.720704}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=215816.050847 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.971123118625\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.943080111529\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.790062887088\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:47.364] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 314, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=1.0284068728\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=33, train mse <loss>=1.05762069603\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.793253005923\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 316.6680335998535, \"sum\": 316.6680335998535, \"min\": 316.6680335998535}}, \"EndTime\": 1588886027.364623, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886027.047426}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2449, \"sum\": 2449.0, \"min\": 2449}, \"Total Records Seen\": {\"count\": 1, \"max\": 2400884, \"sum\": 2400884.0, \"min\": 2400884}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1588886027.364906, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 33}, \"StartTime\": 1588886027.047918}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=222570.260389 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.968686581894\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.938353693941\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.787875384632\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:47.691] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 325, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=1.02620228419\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=34, train mse <loss>=1.05309112808\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.791092285661\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.2538185119629, \"sum\": 327.2538185119629, \"min\": 327.2538185119629}}, \"EndTime\": 1588886027.692494, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886027.36471}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2521, \"sum\": 2521.0, \"min\": 2521}, \"Total Records Seen\": {\"count\": 1, \"max\": 2471469, \"sum\": 2471469.0, \"min\": 2471469}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1588886027.692719, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 34}, \"StartTime\": 1588886027.365206}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=215431.450822 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.966304175165\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.93374375894\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:47 INFO 139783205549888] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.785718092736\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:48.010] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 316, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=1.02404538467\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=35, train mse <loss>=1.04866894987\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.788983726885\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.61400604248047, \"sum\": 318.61400604248047, \"min\": 318.61400604248047}}, \"EndTime\": 1588886028.011621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886027.692569}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2593, \"sum\": 2593.0, \"min\": 2593}, \"Total Records Seen\": {\"count\": 1, \"max\": 2542054, \"sum\": 2542054.0, \"min\": 2542054}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1588886028.011868, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 35}, \"StartTime\": 1588886027.692971}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=221247.430412 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.963974898412\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.929247604769\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.783591072804\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:48.330] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 317, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=1.02193518228\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=36, train mse <loss>=1.04435151678\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.786928596045\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.0600872039795, \"sum\": 319.0600872039795, \"min\": 319.0600872039795}}, \"EndTime\": 1588886028.331255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886028.011692}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2665, \"sum\": 2665.0, \"min\": 2665}, \"Total Records Seen\": {\"count\": 1, \"max\": 2612639, \"sum\": 2612639.0, \"min\": 2612639}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1588886028.331503, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 36}, \"StartTime\": 1588886028.012157}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=220929.60358 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.961697605308\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.924862284056\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.781505807305\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:48.642] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 308, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=1.01987066113\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=37, train mse <loss>=1.04013616544\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.784924549569\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.20920181274414, \"sum\": 311.20920181274414, \"min\": 311.20920181274414}}, \"EndTime\": 1588886028.643044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886028.331337}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2737, \"sum\": 2737.0, \"min\": 2737}, \"Total Records Seen\": {\"count\": 1, \"max\": 2683224, \"sum\": 2683224.0, \"min\": 2683224}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1588886028.643277, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 37}, \"StartTime\": 1588886028.331803}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=226521.639008 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.959471194063\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.920584972236\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.779470585721\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:48.952] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 307, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=1.01785083191\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=38, train mse <loss>=1.03602031603\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.782968683582\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.0949058532715, \"sum\": 309.0949058532715, \"min\": 309.0949058532715}}, \"EndTime\": 1588886028.952644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886028.643123}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2809, \"sum\": 2809.0, \"min\": 2809}, \"Total Records Seen\": {\"count\": 1, \"max\": 2753809, \"sum\": 2753809.0, \"min\": 2753809}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1588886028.952863, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 38}, \"StartTime\": 1588886028.64352}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=228090.923466 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.957294640617\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.916413028955\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:48 INFO 139783205549888] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.777468276456\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:49.361] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 407, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=1.01587471203\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=39, train mse <loss>=1.03200143055\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.781060746498\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 409.8968505859375, \"sum\": 409.8968505859375, \"min\": 409.8968505859375}}, \"EndTime\": 1588886029.363094, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886028.952716}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2881, \"sum\": 2881.0, \"min\": 2881}, \"Total Records Seen\": {\"count\": 1, \"max\": 2824394, \"sum\": 2824394.0, \"min\": 2824394}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1588886029.363582, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 39}, \"StartTime\": 1588886028.953091}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=171886.926268 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.955166775095\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.912343568245\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.775489239146\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:49.660] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 294, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=1.01394127311\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=40, train mse <loss>=1.02807690531\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.779200040705\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.52397537231445, \"sum\": 297.52397537231445, \"min\": 297.52397537231445}}, \"EndTime\": 1588886029.661523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886029.363188}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2953, \"sum\": 2953.0, \"min\": 2953}, \"Total Records Seen\": {\"count\": 1, \"max\": 2894979, \"sum\": 2894979.0, \"min\": 2894979}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1588886029.6618, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 40}, \"StartTime\": 1588886029.363959}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=236844.147747 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.953086570652\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.908374011157\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.773568351024\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:49.974] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 310, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=1.01204952523\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=41, train mse <loss>=1.02424424152\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.777385377362\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.2009506225586, \"sum\": 313.2009506225586, \"min\": 313.2009506225586}}, \"EndTime\": 1588886029.975329, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886029.661614}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3025, \"sum\": 3025.0, \"min\": 3025}, \"Total Records Seen\": {\"count\": 1, \"max\": 2965564, \"sum\": 2965564.0, \"min\": 2965564}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1588886029.975616, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 41}, \"StartTime\": 1588886029.662092}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=225042.376006 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.951052822782\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.904501471721\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:49 INFO 139783205549888] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.771682033117\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:50.290] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 312, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=1.01019845699\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=42, train mse <loss>=1.02050092251\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.775611147421\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.0210380554199, \"sum\": 315.0210380554199, \"min\": 315.0210380554199}}, \"EndTime\": 1588886030.290911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886029.975452}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3097, \"sum\": 3097.0, \"min\": 3097}, \"Total Records Seen\": {\"count\": 1, \"max\": 3036149, \"sum\": 3036149.0, \"min\": 3036149}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1588886030.291144, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 42}, \"StartTime\": 1588886029.975856}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=223778.853679 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.94906450381\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.900723432391\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.769824145066\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:50.585] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 292, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=1.00838707159\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=43, train mse <loss>=1.01684448614\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.773877390114\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.1381206512451, \"sum\": 295.1381206512451, \"min\": 295.1381206512451}}, \"EndTime\": 1588886030.586583, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886030.290993}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3169, \"sum\": 3169.0, \"min\": 3169}, \"Total Records Seen\": {\"count\": 1, \"max\": 3106734, \"sum\": 3106734.0, \"min\": 3106734}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1588886030.58685, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 43}, \"StartTime\": 1588886030.291408}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=238800.787445 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.94712060321\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.897037437024\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.768024897431\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:50.903] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 314, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=1.00661444076\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=44, train mse <loss>=1.01327263235\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.772180994325\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.3489570617676, \"sum\": 317.3489570617676, \"min\": 317.3489570617676}}, \"EndTime\": 1588886030.904531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886030.586665}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3241, \"sum\": 3241.0, \"min\": 3241}, \"Total Records Seen\": {\"count\": 1, \"max\": 3177319, \"sum\": 3177319.0, \"min\": 3177319}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1588886030.904957, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 44}, \"StartTime\": 1588886030.587144}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=221962.525165 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.945219900899\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.893440661056\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:50 INFO 139783205549888] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.766302404269\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:51.229] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 321, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=1.00487955684\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=45, train mse <loss>=1.00978292375\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.770522208228\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.39708709716797, \"sum\": 324.39708709716797, \"min\": 324.39708709716797}}, \"EndTime\": 1588886031.229794, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886030.904666}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3313, \"sum\": 3313.0, \"min\": 3313}, \"Total Records Seen\": {\"count\": 1, \"max\": 3247904, \"sum\": 3247904.0, \"min\": 3247904}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1588886031.230079, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 45}, \"StartTime\": 1588886030.905356}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=217270.812912 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.943361551456\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.889931016765\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.764638981349\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:51.559] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 326, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=1.00318144163\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=46, train mse <loss>=1.00637300484\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.76890139939\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.0259838104248, \"sum\": 329.0259838104248, \"min\": 329.0259838104248}}, \"EndTime\": 1588886031.559616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886031.229884}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3385, \"sum\": 3385.0, \"min\": 3385}, \"Total Records Seen\": {\"count\": 1, \"max\": 3318489, \"sum\": 3318489.0, \"min\": 3318489}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1588886031.559876, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 46}, \"StartTime\": 1588886031.230553}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=214234.195447 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.941544305694\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.886505679585\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.763007181271\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:51.865] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 303, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=1.0015191722\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=47, train mse <loss>=1.00304065229\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.767316305262\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.7830333709717, \"sum\": 305.7830333709717, \"min\": 305.7830333709717}}, \"EndTime\": 1588886031.866013, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886031.559691}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3457, \"sum\": 3457.0, \"min\": 3457}, \"Total Records Seen\": {\"count\": 1, \"max\": 3389074, \"sum\": 3389074.0, \"min\": 3389074}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1588886031.866305, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 47}, \"StartTime\": 1588886031.560201}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=230478.510576 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.939767127952\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.883162254779\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:51 INFO 139783205549888] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.761410995268\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:52.163] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 294, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.999891843262\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.999783698222\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.765768376501\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.2698211669922, \"sum\": 297.2698211669922, \"min\": 297.2698211669922}}, \"EndTime\": 1588886032.163907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886031.866097}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3529, \"sum\": 3529.0, \"min\": 3529}, \"Total Records Seen\": {\"count\": 1, \"max\": 3459659, \"sum\": 3459659.0, \"min\": 3459659}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1588886032.164171, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 48}, \"StartTime\": 1588886031.8666}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=237088.443875 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.938029165872\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.879898716027\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.75985865142\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:52.473] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 307, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.998298453177\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.996599801616\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.764254776605\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.0559711456299, \"sum\": 310.0559711456299, \"min\": 310.0559711456299}}, \"EndTime\": 1588886032.47457, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886032.163988}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3601, \"sum\": 3601.0, \"min\": 3601}, \"Total Records Seen\": {\"count\": 1, \"max\": 3530244, \"sum\": 3530244.0, \"min\": 3530244}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1588886032.474802, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 49}, \"StartTime\": 1588886032.164479}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=227354.01961 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=0.936329260666\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=50, batch=0 train mse <loss>=0.876712484379\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=50, batch=0 train absolute_loss <loss>=0.758329763739\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:52.792] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 316, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=0.996738141395\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=50, train mse <loss>=0.993486922512\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=50, train absolute_loss <loss>=0.762773843412\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.3441162109375, \"sum\": 318.3441162109375, \"min\": 318.3441162109375}}, \"EndTime\": 1588886032.793428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886032.474648}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3673, \"sum\": 3673.0, \"min\": 3673}, \"Total Records Seen\": {\"count\": 1, \"max\": 3600829, \"sum\": 3600829.0, \"min\": 3600829}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 52, \"sum\": 52.0, \"min\": 52}}, \"EndTime\": 1588886032.79365, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 50}, \"StartTime\": 1588886032.475052}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=221457.780358 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=0.934666503152\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=51, batch=0 train mse <loss>=0.873601472114\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:52 INFO 139783205549888] #quality_metric: host=algo-1, epoch=51, batch=0 train absolute_loss <loss>=0.756821323449\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:53.107] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 312, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=0.995210040322\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=51, train mse <loss>=0.990443024357\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=51, train absolute_loss <loss>=0.761323466174\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.56494331359863, \"sum\": 314.56494331359863, \"min\": 314.56494331359863}}, \"EndTime\": 1588886033.108495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886032.7935}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3745, \"sum\": 3745.0, \"min\": 3745}, \"Total Records Seen\": {\"count\": 1, \"max\": 3671414, \"sum\": 3671414.0, \"min\": 3671414}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 53, \"sum\": 53.0, \"min\": 53}}, \"EndTime\": 1588886033.108708, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 51}, \"StartTime\": 1588886032.793902}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=224129.877206 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=0.933039940253\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=52, batch=0 train mse <loss>=0.870563530106\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=52, batch=0 train absolute_loss <loss>=0.755330813003\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:53.419] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 309, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=0.993713241225\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=52, train mse <loss>=0.987466005785\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=52, train absolute_loss <loss>=0.759905110902\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.43808364868164, \"sum\": 311.43808364868164, \"min\": 311.43808364868164}}, \"EndTime\": 1588886033.42057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886033.108568}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3817, \"sum\": 3817.0, \"min\": 3817}, \"Total Records Seen\": {\"count\": 1, \"max\": 3741999, \"sum\": 3741999.0, \"min\": 3741999}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 54, \"sum\": 54.0, \"min\": 54}}, \"EndTime\": 1588886033.420823, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 52}, \"StartTime\": 1588886033.109097}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=226334.089557 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=0.931448476093\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=53, batch=0 train mse <loss>=0.867596263617\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=53, batch=0 train absolute_loss <loss>=0.753858478017\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:53.733] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 310, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=0.992246890041\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=53, train mse <loss>=0.984553890795\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=53, train absolute_loss <loss>=0.758516433173\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.4380111694336, \"sum\": 312.4380111694336, \"min\": 312.4380111694336}}, \"EndTime\": 1588886033.733599, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886033.420645}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3889, \"sum\": 3889.0, \"min\": 3889}, \"Total Records Seen\": {\"count\": 1, \"max\": 3812584, \"sum\": 3812584.0, \"min\": 3812584}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}}, \"EndTime\": 1588886033.733831, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 53}, \"StartTime\": 1588886033.421129}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=225639.598375 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=0.929891168322\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=54, batch=0 train mse <loss>=0.864697584924\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:53 INFO 139783205549888] #quality_metric: host=algo-1, epoch=54, batch=0 train absolute_loss <loss>=0.752420406226\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:54.026] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 291, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=0.990810129524\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=54, train mse <loss>=0.981704712767\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=54, train absolute_loss <loss>=0.757157235985\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 293.3199405670166, \"sum\": 293.3199405670166, \"min\": 293.3199405670166}}, \"EndTime\": 1588886034.027444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886033.73367}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3961, \"sum\": 3961.0, \"min\": 3961}, \"Total Records Seen\": {\"count\": 1, \"max\": 3883169, \"sum\": 3883169.0, \"min\": 3883169}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 56, \"sum\": 56.0, \"min\": 56}}, \"EndTime\": 1588886034.027699, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 54}, \"StartTime\": 1588886033.734093}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=240299.269528 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=0.928367262847\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=55, batch=0 train mse <loss>=0.861865774726\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=55, batch=0 train absolute_loss <loss>=0.751012790611\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:54.398] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 368, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=0.989402172319\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=55, train mse <loss>=0.978916658589\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=55, train absolute_loss <loss>=0.755826113876\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 370.76807022094727, \"sum\": 370.76807022094727, \"min\": 370.76807022094727}}, \"EndTime\": 1588886034.398751, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886034.027526}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4033, \"sum\": 4033.0, \"min\": 4033}, \"Total Records Seen\": {\"count\": 1, \"max\": 3953754, \"sum\": 3953754.0, \"min\": 3953754}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 57, \"sum\": 57.0, \"min\": 57}}, \"EndTime\": 1588886034.399061, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 55}, \"StartTime\": 1588886034.027944}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=190123.350353 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=0.926875698836\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=56, batch=0 train mse <loss>=0.859098561093\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=56, batch=0 train absolute_loss <loss>=0.749631885552\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:54.714] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 312, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=0.988022201142\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=56, train mse <loss>=0.97618786995\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=56, train absolute_loss <loss>=0.754522183318\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.72699546813965, \"sum\": 315.72699546813965, \"min\": 315.72699546813965}}, \"EndTime\": 1588886034.715145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886034.398835}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4105, \"sum\": 4105.0, \"min\": 4105}, \"Total Records Seen\": {\"count\": 1, \"max\": 4024339, \"sum\": 4024339.0, \"min\": 4024339}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 58, \"sum\": 58.0, \"min\": 58}}, \"EndTime\": 1588886034.71543, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 56}, \"StartTime\": 1588886034.39938}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=223221.214023 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=0.925415571032\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=57, batch=0 train mse <loss>=0.856393979109\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:54 INFO 139783205549888] #quality_metric: host=algo-1, epoch=57, batch=0 train absolute_loss <loss>=0.748267620862\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:55.049] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 331, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=0.986669402947\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=57, train mse <loss>=0.973516510712\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=57, train absolute_loss <loss>=0.753243752302\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 333.85300636291504, \"sum\": 333.85300636291504, \"min\": 333.85300636291504}}, \"EndTime\": 1588886035.049639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886034.715236}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4177, \"sum\": 4177.0, \"min\": 4177}, \"Total Records Seen\": {\"count\": 1, \"max\": 4094924, \"sum\": 4094924.0, \"min\": 4094924}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 59, \"sum\": 59.0, \"min\": 59}}, \"EndTime\": 1588886035.049943, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 57}, \"StartTime\": 1588886034.715746}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=211114.956316 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=0.923986098096\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=58, batch=0 train mse <loss>=0.853750309474\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=58, batch=0 train absolute_loss <loss>=0.746931540414\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:55.351] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 299, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=0.98534302717\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=58, train mse <loss>=0.970900881192\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=58, train absolute_loss <loss>=0.751992271486\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.0169734954834, \"sum\": 302.0169734954834, \"min\": 302.0169734954834}}, \"EndTime\": 1588886035.352351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886035.049731}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4249, \"sum\": 4249.0, \"min\": 4249}, \"Total Records Seen\": {\"count\": 1, \"max\": 4165509, \"sum\": 4165509.0, \"min\": 4165509}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 60, \"sum\": 60.0, \"min\": 60}}, \"EndTime\": 1588886035.352616, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 58}, \"StartTime\": 1588886035.050249}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=233330.376136 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=0.922586157956\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=59, batch=0 train mse <loss>=0.851165218852\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=59, batch=0 train absolute_loss <loss>=0.745646424936\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:55.679] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 324, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=0.984042281495\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=59, train mse <loss>=0.968339211771\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=59, train absolute_loss <loss>=0.750767317017\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.3348808288574, \"sum\": 327.3348808288574, \"min\": 327.3348808288574}}, \"EndTime\": 1588886035.680278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886035.352432}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4321, \"sum\": 4321.0, \"min\": 4321}, \"Total Records Seen\": {\"count\": 1, \"max\": 4236094, \"sum\": 4236094.0, \"min\": 4236094}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 61, \"sum\": 61.0, \"min\": 61}}, \"EndTime\": 1588886035.680523, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 59}, \"StartTime\": 1588886035.352905}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=215351.844219 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=0.921215185377\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=60, batch=0 train mse <loss>=0.848637417768\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=60, batch=0 train absolute_loss <loss>=0.744384151589\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:55.980] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 297, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=0.982766483652\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=60, train mse <loss>=0.96582996139\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=60, train absolute_loss <loss>=0.749567928608\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 299.6060848236084, \"sum\": 299.6060848236084, \"min\": 299.6060848236084}}, \"EndTime\": 1588886035.980458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886035.680346}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4393, \"sum\": 4393.0, \"min\": 4393}, \"Total Records Seen\": {\"count\": 1, \"max\": 4306679, \"sum\": 4306679.0, \"min\": 4306679}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 62, \"sum\": 62.0, \"min\": 62}}, \"EndTime\": 1588886035.980658, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 60}, \"StartTime\": 1588886035.680823}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=235324.140841 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=0.919872308592\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=61, batch=0 train mse <loss>=0.846165064115\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:55 INFO 139783205549888] #quality_metric: host=algo-1, epoch=61, batch=0 train absolute_loss <loss>=0.743137351944\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:56.283] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 300, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=0.981514932415\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=61, train mse <loss>=0.963371562553\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=61, train absolute_loss <loss>=0.748390707745\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.85096168518066, \"sum\": 302.85096168518066, \"min\": 302.85096168518066}}, \"EndTime\": 1588886036.283735, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886035.980513}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4465, \"sum\": 4465.0, \"min\": 4465}, \"Total Records Seen\": {\"count\": 1, \"max\": 4377264, \"sum\": 4377264.0, \"min\": 4377264}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 63, \"sum\": 63.0, \"min\": 63}}, \"EndTime\": 1588886036.28402, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 61}, \"StartTime\": 1588886035.980848}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=232711.742404 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=0.918556480989\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=62, batch=0 train mse <loss>=0.843746008767\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=62, batch=0 train absolute_loss <loss>=0.741915850572\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:56.592] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 306, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=0.980286798475\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=62, train mse <loss>=0.960962207265\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=62, train absolute_loss <loss>=0.747236947312\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.0190887451172, \"sum\": 309.0190887451172, \"min\": 309.0190887451172}}, \"EndTime\": 1588886036.593398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886036.283829}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4537, \"sum\": 4537.0, \"min\": 4537}, \"Total Records Seen\": {\"count\": 1, \"max\": 4447849, \"sum\": 4447849.0, \"min\": 4447849}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 64, \"sum\": 64.0, \"min\": 64}}, \"EndTime\": 1588886036.593625, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 62}, \"StartTime\": 1588886036.284344}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=228129.063057 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=0.917267417323\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=63, batch=0 train mse <loss>=0.841379514882\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=63, batch=0 train absolute_loss <loss>=0.74071356852\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:56.905] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 309, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=0.979081552383\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=63, train mse <loss>=0.958600686216\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=63, train absolute_loss <loss>=0.746107050697\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.80310249328613, \"sum\": 311.80310249328613, \"min\": 311.80310249328613}}, \"EndTime\": 1588886036.905685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886036.593476}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4609, \"sum\": 4609.0, \"min\": 4609}, \"Total Records Seen\": {\"count\": 1, \"max\": 4518434, \"sum\": 4518434.0, \"min\": 4518434}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 65, \"sum\": 65.0, \"min\": 65}}, \"EndTime\": 1588886036.905908, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 63}, \"StartTime\": 1588886036.593851}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=226102.11797 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=0.916003856385\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=64, batch=0 train mse <loss>=0.839063064913\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:56 INFO 139783205549888] #quality_metric: host=algo-1, epoch=64, batch=0 train absolute_loss <loss>=0.73953842685\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:57.202] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 295, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=0.977898479919\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=64, train mse <loss>=0.956285437028\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=64, train absolute_loss <loss>=0.744999951866\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.39904403686523, \"sum\": 297.39904403686523, \"min\": 297.39904403686523}}, \"EndTime\": 1588886037.203592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886036.905762}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4681, \"sum\": 4681.0, \"min\": 4681}, \"Total Records Seen\": {\"count\": 1, \"max\": 4589019, \"sum\": 4589019.0, \"min\": 4589019}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 66, \"sum\": 66.0, \"min\": 66}}, \"EndTime\": 1588886037.203879, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 64}, \"StartTime\": 1588886036.906154}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=236974.388976 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=0.914765165483\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=65, batch=0 train mse <loss>=0.836795307981\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=65, batch=0 train absolute_loss <loss>=0.738390486965\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:57.510] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 304, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=0.976736919926\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=65, train mse <loss>=0.954015010746\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=65, train absolute_loss <loss>=0.743913970749\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.6720962524414, \"sum\": 306.6720962524414, \"min\": 306.6720962524414}}, \"EndTime\": 1588886037.510883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886037.203676}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4753, \"sum\": 4753.0, \"min\": 4753}, \"Total Records Seen\": {\"count\": 1, \"max\": 4659604, \"sum\": 4659604.0, \"min\": 4659604}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 67, \"sum\": 67.0, \"min\": 67}}, \"EndTime\": 1588886037.511163, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 65}, \"StartTime\": 1588886037.204172}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=229807.081588 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=0.913550908066\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=66, batch=0 train mse <loss>=0.834575261628\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=66, batch=0 train absolute_loss <loss>=0.737263362892\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:57.825] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 311, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=0.975596225874\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=66, train mse <loss>=0.95178799594\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=66, train absolute_loss <loss>=0.742848255372\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.28003311157227, \"sum\": 314.28003311157227, \"min\": 314.28003311157227}}, \"EndTime\": 1588886037.825793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886037.510973}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4825, \"sum\": 4825.0, \"min\": 4825}, \"Total Records Seen\": {\"count\": 1, \"max\": 4730189, \"sum\": 4730189.0, \"min\": 4730189}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}}, \"EndTime\": 1588886037.826099, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 66}, \"StartTime\": 1588886037.511476}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=224243.959292 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=0.912359970257\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=67, batch=0 train mse <loss>=0.832400715327\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:57 INFO 139783205549888] #quality_metric: host=algo-1, epoch=67, batch=0 train absolute_loss <loss>=0.736176887988\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:58.139] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 311, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=0.974475854924\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=67, train mse <loss>=0.94960319183\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=67, train absolute_loss <loss>=0.741803471791\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.5809898376465, \"sum\": 313.5809898376465, \"min\": 313.5809898376465}}, \"EndTime\": 1588886038.14006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886037.825904}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4897, \"sum\": 4897.0, \"min\": 4897}, \"Total Records Seen\": {\"count\": 1, \"max\": 4800774, \"sum\": 4800774.0, \"min\": 4800774}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 69, \"sum\": 69.0, \"min\": 69}}, \"EndTime\": 1588886038.140291, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 67}, \"StartTime\": 1588886037.826443}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=224803.654386 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=0.911191971775\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=68, batch=0 train mse <loss>=0.830270809427\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=68, batch=0 train absolute_loss <loss>=0.735118904344\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:58.454] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 311, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=0.973375192975\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=68, train mse <loss>=0.947459266299\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=68, train absolute_loss <loss>=0.740776344298\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.1179084777832, \"sum\": 314.1179084777832, \"min\": 314.1179084777832}}, \"EndTime\": 1588886038.454766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886038.140141}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4969, \"sum\": 4969.0, \"min\": 4969}, \"Total Records Seen\": {\"count\": 1, \"max\": 4871359, \"sum\": 4871359.0, \"min\": 4871359}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 70, \"sum\": 70.0, \"min\": 70}}, \"EndTime\": 1588886038.45504, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 68}, \"StartTime\": 1588886038.140613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=224387.065456 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=0.910046123795\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=69, batch=0 train mse <loss>=0.828183947435\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=69, batch=0 train absolute_loss <loss>=0.734095552318\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:58.747] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 290, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=0.9722936592\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=69, train mse <loss>=0.945354959721\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=69, train absolute_loss <loss>=0.739767941484\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.91391372680664, \"sum\": 292.91391372680664, \"min\": 292.91391372680664}}, \"EndTime\": 1588886038.748279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886038.454841}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5041, \"sum\": 5041.0, \"min\": 5041}, \"Total Records Seen\": {\"count\": 1, \"max\": 4941944, \"sum\": 4941944.0, \"min\": 4941944}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 71, \"sum\": 71.0, \"min\": 71}}, \"EndTime\": 1588886038.748527, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 69}, \"StartTime\": 1588886038.455329}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=240625.239536 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=0.908921699413\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=70, batch=0 train mse <loss>=0.826138655664\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:58 INFO 139783205549888] #quality_metric: host=algo-1, epoch=70, batch=0 train absolute_loss <loss>=0.73309602488\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:59.053] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 303, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=0.971230675618\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=70, train mse <loss>=0.943289025262\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=70, train absolute_loss <loss>=0.738779125559\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.25994300842285, \"sum\": 305.25994300842285, \"min\": 305.25994300842285}}, \"EndTime\": 1588886039.054068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886038.748367}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5113, \"sum\": 5113.0, \"min\": 5113}, \"Total Records Seen\": {\"count\": 1, \"max\": 5012529, \"sum\": 5012529.0, \"min\": 5012529}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}}, \"EndTime\": 1588886039.054323, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 70}, \"StartTime\": 1588886038.748775}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=230906.880559 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=0.907818338584\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=71, batch=0 train mse <loss>=0.82413413587\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=71, batch=0 train absolute_loss <loss>=0.732118541326\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:59.371] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 314, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=0.970185783254\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=71, train mse <loss>=0.941260454027\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=71, train absolute_loss <loss>=0.737809390796\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.0430660247803, \"sum\": 317.0430660247803, \"min\": 317.0430660247803}}, \"EndTime\": 1588886039.371661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886039.054143}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5185, \"sum\": 5185.0, \"min\": 5185}, \"Total Records Seen\": {\"count\": 1, \"max\": 5083114, \"sum\": 5083114.0, \"min\": 5083114}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 73, \"sum\": 73.0, \"min\": 73}}, \"EndTime\": 1588886039.371938, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 71}, \"StartTime\": 1588886039.054578}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=222316.382983 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=0.906735068551\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=72, batch=0 train mse <loss>=0.82216848454\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=72, batch=0 train absolute_loss <loss>=0.731167645522\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:13:59.715] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 341, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=0.969158411884\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=72, train mse <loss>=0.939268027326\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=72, train absolute_loss <loss>=0.736858349158\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 343.2948589324951, \"sum\": 343.2948589324951, \"min\": 343.2948589324951}}, \"EndTime\": 1588886039.715576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886039.371749}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5257, \"sum\": 5257.0, \"min\": 5257}, \"Total Records Seen\": {\"count\": 1, \"max\": 5153699, \"sum\": 5153699.0, \"min\": 5153699}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 74, \"sum\": 74.0, \"min\": 74}}, \"EndTime\": 1588886039.715819, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 72}, \"StartTime\": 1588886039.372246}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=205362.680762 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=0.90567162241\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=73, batch=0 train mse <loss>=0.820241087639\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:13:59 INFO 139783205549888] #quality_metric: host=algo-1, epoch=73, batch=0 train absolute_loss <loss>=0.730239898866\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:00.018] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 300, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=0.96814807026\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=73, train mse <loss>=0.937310685947\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=73, train absolute_loss <loss>=0.735924464703\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.86312103271484, \"sum\": 302.86312103271484, \"min\": 302.86312103271484}}, \"EndTime\": 1588886040.018972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886039.715657}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5329, \"sum\": 5329.0, \"min\": 5329}, \"Total Records Seen\": {\"count\": 1, \"max\": 5224284, \"sum\": 5224284.0, \"min\": 5224284}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 75, \"sum\": 75.0, \"min\": 75}}, \"EndTime\": 1588886040.019246, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 73}, \"StartTime\": 1588886039.716072}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=232712.657015 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=0.904627357364\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=74, batch=0 train mse <loss>=0.818350655692\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=74, batch=0 train absolute_loss <loss>=0.729328239947\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:00.326] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 304, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=0.967154241231\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=74, train mse <loss>=0.935387326332\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=74, train absolute_loss <loss>=0.735005896176\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.4679374694824, \"sum\": 307.4679374694824, \"min\": 307.4679374694824}}, \"EndTime\": 1588886040.327063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886040.019055}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5401, \"sum\": 5401.0, \"min\": 5401}, \"Total Records Seen\": {\"count\": 1, \"max\": 5294869, \"sum\": 5294869.0, \"min\": 5294869}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 76, \"sum\": 76.0, \"min\": 76}}, \"EndTime\": 1588886040.32738, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 74}, \"StartTime\": 1588886040.019551}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=229175.205863 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=0.903601558441\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=75, batch=0 train mse <loss>=0.816495776416\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=75, batch=0 train absolute_loss <loss>=0.728433282802\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:00.650] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 318, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=0.966176504403\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=75, train mse <loss>=0.933497037659\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=75, train absolute_loss <loss>=0.734102000546\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.77099990844727, \"sum\": 323.77099990844727, \"min\": 323.77099990844727}}, \"EndTime\": 1588886040.651534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886040.327163}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5473, \"sum\": 5473.0, \"min\": 5473}, \"Total Records Seen\": {\"count\": 1, \"max\": 5365454, \"sum\": 5365454.0, \"min\": 5365454}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 77, \"sum\": 77.0, \"min\": 77}}, \"EndTime\": 1588886040.651776, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 75}, \"StartTime\": 1588886040.327724}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=217747.502319 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=0.902593914434\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=76, batch=0 train mse <loss>=0.814675774373\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=76, batch=0 train absolute_loss <loss>=0.727555518659\u001b[0m\n",
      "\n",
      "2020-05-07 21:14:09 Uploading - Uploading generated training model\u001b[34m[2020-05-07 21:14:00.962] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 308, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=0.965214387374\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=76, train mse <loss>=0.931638813594\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=76, train absolute_loss <loss>=0.733213909515\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.00010871887207, \"sum\": 311.00010871887207, \"min\": 311.00010871887207}}, \"EndTime\": 1588886040.963055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886040.651641}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5545, \"sum\": 5545.0, \"min\": 5545}, \"Total Records Seen\": {\"count\": 1, \"max\": 5436039, \"sum\": 5436039.0, \"min\": 5436039}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 78, \"sum\": 78.0, \"min\": 78}}, \"EndTime\": 1588886040.963328, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 76}, \"StartTime\": 1588886040.65202}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=226620.994559 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=0.901603771114\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=77, batch=0 train mse <loss>=0.812889360086\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:00 INFO 139783205549888] #quality_metric: host=algo-1, epoch=77, batch=0 train absolute_loss <loss>=0.726686043998\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:01.262] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 297, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=0.964267452234\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=77, train mse <loss>=0.929811719438\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=77, train absolute_loss <loss>=0.732342386363\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 299.4349002838135, \"sum\": 299.4349002838135, \"min\": 299.4349002838135}}, \"EndTime\": 1588886041.263122, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886040.963139}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5617, \"sum\": 5617.0, \"min\": 5617}, \"Total Records Seen\": {\"count\": 1, \"max\": 5506624, \"sum\": 5506624.0, \"min\": 5506624}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 79, \"sum\": 79.0, \"min\": 79}}, \"EndTime\": 1588886041.263409, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 77}, \"StartTime\": 1588886040.963651}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=235357.066469 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=0.900630674862\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=78, batch=0 train mse <loss>=0.811135612503\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=78, batch=0 train absolute_loss <loss>=0.725832964093\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:01.585] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 320, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=0.963335296682\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=78, train mse <loss>=0.928014893833\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=78, train absolute_loss <loss>=0.731483775019\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.6809501647949, \"sum\": 322.6809501647949, \"min\": 322.6809501647949}}, \"EndTime\": 1588886041.586433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886041.263213}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5689, \"sum\": 5689.0, \"min\": 5689}, \"Total Records Seen\": {\"count\": 1, \"max\": 5577209, \"sum\": 5577209.0, \"min\": 5577209}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 80, \"sum\": 80.0, \"min\": 80}}, \"EndTime\": 1588886041.586673, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 78}, \"StartTime\": 1588886041.263719}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=218472.678155 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=0.899674169113\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=79, batch=0 train mse <loss>=0.80941361057\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=79, batch=0 train absolute_loss <loss>=0.724988173671\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:01.891] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 303, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=0.96241750066\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=79, train mse <loss>=0.926247445577\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=79, train absolute_loss <loss>=0.730638344123\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.6519031524658, \"sum\": 305.6519031524658, \"min\": 305.6519031524658}}, \"EndTime\": 1588886041.892616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886041.58651}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5761, \"sum\": 5761.0, \"min\": 5761}, \"Total Records Seen\": {\"count\": 1, \"max\": 5647794, \"sum\": 5647794.0, \"min\": 5647794}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 81, \"sum\": 81.0, \"min\": 81}}, \"EndTime\": 1588886041.892907, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 79}, \"StartTime\": 1588886041.586929}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=230570.413992 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=0.898733828581\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=80, batch=0 train mse <loss>=0.807722494636\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:01 INFO 139783205549888] #quality_metric: host=algo-1, epoch=80, batch=0 train absolute_loss <loss>=0.7241511201\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:02.216] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 321, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=0.961513645398\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=80, train mse <loss>=0.924508490286\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=80, train absolute_loss <loss>=0.729806566142\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.0940570831299, \"sum\": 324.0940570831299, \"min\": 324.0940570831299}}, \"EndTime\": 1588886042.217341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886041.89271}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5833, \"sum\": 5833.0, \"min\": 5833}, \"Total Records Seen\": {\"count\": 1, \"max\": 5718379, \"sum\": 5718379.0, \"min\": 5718379}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 82, \"sum\": 82.0, \"min\": 82}}, \"EndTime\": 1588886042.217573, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 80}, \"StartTime\": 1588886041.893211}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=217522.560353 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=0.897809122721\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=81, batch=0 train mse <loss>=0.806061220841\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=81, batch=0 train absolute_loss <loss>=0.723321741975\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:02.537] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 318, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=0.960623383615\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=81, train mse <loss>=0.922797285149\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=81, train absolute_loss <loss>=0.7289881315\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.7380771636963, \"sum\": 320.7380771636963, \"min\": 320.7380771636963}}, \"EndTime\": 1588886042.538585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886042.21742}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5905, \"sum\": 5905.0, \"min\": 5905}, \"Total Records Seen\": {\"count\": 1, \"max\": 5788964, \"sum\": 5788964.0, \"min\": 5788964}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 83, \"sum\": 83.0, \"min\": 83}}, \"EndTime\": 1588886042.538834, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 81}, \"StartTime\": 1588886042.217811}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=219782.832386 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=0.896899586426\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=82, batch=0 train mse <loss>=0.804428868131\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=82, batch=0 train absolute_loss <loss>=0.72250126737\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:02.856] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 316, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=0.959746333723\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=82, train mse <loss>=0.921113025095\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=82, train absolute_loss <loss>=0.72818328837\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.95811653137207, \"sum\": 317.95811653137207, \"min\": 317.95811653137207}}, \"EndTime\": 1588886042.857098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886042.538671}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5977, \"sum\": 5977.0, \"min\": 5977}, \"Total Records Seen\": {\"count\": 1, \"max\": 5859549, \"sum\": 5859549.0, \"min\": 5859549}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 84, \"sum\": 84.0, \"min\": 84}}, \"EndTime\": 1588886042.857328, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 82}, \"StartTime\": 1588886042.539104}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=221713.020182 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=83, batch=0 train rmse <loss>=0.896004957505\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=83, batch=0 train mse <loss>=0.802824883874\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:02 INFO 139783205549888] #quality_metric: host=algo-1, epoch=83, batch=0 train absolute_loss <loss>=0.72169393313\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:03.167] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 168, \"duration\": 308, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=83, train rmse <loss>=0.958882136192\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=83, train mse <loss>=0.919454951108\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=83, train absolute_loss <loss>=0.727391658948\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.58406829833984, \"sum\": 310.58406829833984, \"min\": 310.58406829833984}}, \"EndTime\": 1588886043.16825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886042.857176}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6049, \"sum\": 6049.0, \"min\": 6049}, \"Total Records Seen\": {\"count\": 1, \"max\": 5930134, \"sum\": 5930134.0, \"min\": 5930134}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 85, \"sum\": 85.0, \"min\": 85}}, \"EndTime\": 1588886043.168534, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 83}, \"StartTime\": 1588886042.857583}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=226894.367964 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=84, batch=0 train rmse <loss>=0.895124697575\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=84, batch=0 train mse <loss>=0.801248224209\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=84, batch=0 train absolute_loss <loss>=0.720897712938\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:03.472] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 170, \"duration\": 301, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=84, train rmse <loss>=0.958030447918\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=84, train mse <loss>=0.917822339139\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=84, train absolute_loss <loss>=0.72661299762\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.0599822998047, \"sum\": 304.0599822998047, \"min\": 304.0599822998047}}, \"EndTime\": 1588886043.472912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886043.16835}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6121, \"sum\": 6121.0, \"min\": 6121}, \"Total Records Seen\": {\"count\": 1, \"max\": 6000719, \"sum\": 6000719.0, \"min\": 6000719}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 86, \"sum\": 86.0, \"min\": 86}}, \"EndTime\": 1588886043.473177, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 84}, \"StartTime\": 1588886043.168814}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=231791.642205 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=85, batch=0 train rmse <loss>=0.894258505746\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=85, batch=0 train mse <loss>=0.7996982751\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=85, batch=0 train absolute_loss <loss>=0.720110519071\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:03.783] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 172, \"duration\": 308, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=85, train rmse <loss>=0.957190950806\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=85, train mse <loss>=0.916214516305\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=85, train absolute_loss <loss>=0.725846605069\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.72998046875, \"sum\": 310.72998046875, \"min\": 310.72998046875}}, \"EndTime\": 1588886043.784253, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886043.473003}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6193, \"sum\": 6193.0, \"min\": 6193}, \"Total Records Seen\": {\"count\": 1, \"max\": 6071304, \"sum\": 6071304.0, \"min\": 6071304}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 87, \"sum\": 87.0, \"min\": 87}}, \"EndTime\": 1588886043.784482, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 85}, \"StartTime\": 1588886043.473488}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=226873.850775 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=86, batch=0 train rmse <loss>=0.89340601056\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=86, batch=0 train mse <loss>=0.798174299704\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:03 INFO 139783205549888] #quality_metric: host=algo-1, epoch=86, batch=0 train absolute_loss <loss>=0.719336342764\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:04.096] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 174, \"duration\": 310, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=86, train rmse <loss>=0.956363355487\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=86, train mse <loss>=0.914630867719\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=86, train absolute_loss <loss>=0.725092054026\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.37077713012695, \"sum\": 312.37077713012695, \"min\": 312.37077713012695}}, \"EndTime\": 1588886044.097174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886043.784331}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6265, \"sum\": 6265.0, \"min\": 6265}, \"Total Records Seen\": {\"count\": 1, \"max\": 6141889, \"sum\": 6141889.0, \"min\": 6141889}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 88, \"sum\": 88.0, \"min\": 88}}, \"EndTime\": 1588886044.097385, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 86}, \"StartTime\": 1588886043.78477}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=225701.525368 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=87, batch=0 train rmse <loss>=0.892566735303\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=87, batch=0 train mse <loss>=0.796675376969\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=87, batch=0 train absolute_loss <loss>=0.718577087525\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:04.414] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 176, \"duration\": 315, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=87, train rmse <loss>=0.955547255561\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=87, train mse <loss>=0.913070557609\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=87, train absolute_loss <loss>=0.724349057944\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.2171115875244, \"sum\": 317.2171115875244, \"min\": 317.2171115875244}}, \"EndTime\": 1588886044.414863, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886044.097243}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6337, \"sum\": 6337.0, \"min\": 6337}, \"Total Records Seen\": {\"count\": 1, \"max\": 6212474, \"sum\": 6212474.0, \"min\": 6212474}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 89, \"sum\": 89.0, \"min\": 89}}, \"EndTime\": 1588886044.415087, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 87}, \"StartTime\": 1588886044.097614}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=222246.455482 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=88, batch=0 train rmse <loss>=0.891740476298\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=88, batch=0 train mse <loss>=0.795201077068\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=88, batch=0 train absolute_loss <loss>=0.717824525277\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:04.754] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 178, \"duration\": 337, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=88, train rmse <loss>=0.954742484882\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=88, train mse <loss>=0.911533212438\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=88, train absolute_loss <loss>=0.723618025325\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 339.3681049346924, \"sum\": 339.3681049346924, \"min\": 339.3681049346924}}, \"EndTime\": 1588886044.754733, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886044.41494}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6409, \"sum\": 6409.0, \"min\": 6409}, \"Total Records Seen\": {\"count\": 1, \"max\": 6283059, \"sum\": 6283059.0, \"min\": 6283059}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 90, \"sum\": 90.0, \"min\": 90}}, \"EndTime\": 1588886044.755003, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 88}, \"StartTime\": 1588886044.415331}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=207724.622194 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=89, batch=0 train rmse <loss>=0.890926718392\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=89, batch=0 train mse <loss>=0.793750417544\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:04 INFO 139783205549888] #quality_metric: host=algo-1, epoch=89, batch=0 train absolute_loss <loss>=0.71708504199\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:05.076] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 180, \"duration\": 319, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=89, train rmse <loss>=0.953948638087\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=89, train mse <loss>=0.910018004109\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=89, train absolute_loss <loss>=0.722897979682\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.0179080963135, \"sum\": 322.0179080963135, \"min\": 322.0179080963135}}, \"EndTime\": 1588886045.077299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886044.754804}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6481, \"sum\": 6481.0, \"min\": 6481}, \"Total Records Seen\": {\"count\": 1, \"max\": 6353644, \"sum\": 6353644.0, \"min\": 6353644}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}}, \"EndTime\": 1588886045.077561, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 89}, \"StartTime\": 1588886044.755251}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=218911.595976 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=90, batch=0 train rmse <loss>=0.890125392396\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=90, batch=0 train mse <loss>=0.792323214187\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=90, batch=0 train absolute_loss <loss>=0.716365085041\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:05.400] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 182, \"duration\": 320, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=90, train rmse <loss>=0.953165545184\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=90, train mse <loss>=0.908524556526\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, epoch=90, train absolute_loss <loss>=0.72218869928\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, train rmse <loss>=0.953165545184\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, train mse <loss>=0.908524556526\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, train absolute_loss <loss>=0.72218869928\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.12583923339844, \"sum\": 323.12583923339844, \"min\": 323.12583923339844}}, \"EndTime\": 1588886045.401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886045.077384}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6553, \"sum\": 6553.0, \"min\": 6553}, \"Total Records Seen\": {\"count\": 1, \"max\": 6424229, \"sum\": 6424229.0, \"min\": 6424229}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 70585, \"sum\": 70585.0, \"min\": 70585}, \"Reset Count\": {\"count\": 1, \"max\": 92, \"sum\": 92.0, \"min\": 92}}, \"EndTime\": 1588886045.401211, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 90}, \"StartTime\": 1588886045.077844}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #throughput_metric: host=algo-1, train throughput=218195.568533 records/second\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 WARNING 139783205549888] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 3.737926483154297, \"sum\": 3.737926483154297, \"min\": 3.737926483154297}}, \"EndTime\": 1588886045.405249, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886045.401069}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] Saved checkpoint to \"/tmp/tmpd4LtXI/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:05.412] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 29416, \"num_examples\": 1, \"num_bytes\": 63616}\u001b[0m\n",
      "\u001b[34m[2020-05-07 21:14:05.539] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 127, \"num_examples\": 31, \"num_bytes\": 1936064}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30251, \"sum\": 30251.0, \"min\": 30251}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Total Records Seen\": {\"count\": 1, \"max\": 30251, \"sum\": 30251.0, \"min\": 30251}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30251, \"sum\": 30251.0, \"min\": 30251}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1588886045.539972, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886045.411881}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #test_score (algo-1) : ('rmse', 0.9026666789823493)\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #test_score (algo-1) : ('mse', 0.8148071333450237)\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #test_score (algo-1) : ('absolute_loss', 0.7177793299721109)\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, test rmse <loss>=0.902666678982\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, test mse <loss>=0.814807133345\u001b[0m\n",
      "\u001b[34m[05/07/2020 21:14:05 INFO 139783205549888] #quality_metric: host=algo-1, test absolute_loss <loss>=0.717779329972\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 29607.13481903076, \"sum\": 29607.13481903076, \"min\": 29607.13481903076}, \"setuptime\": {\"count\": 1, \"max\": 51.97000503540039, \"sum\": 51.97000503540039, \"min\": 51.97000503540039}}, \"EndTime\": 1588886045.541141, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1588886045.405312}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-07 21:14:16 Completed - Training job completed\n",
      "Training seconds: 96\n",
      "Billable seconds: 96\n"
     ]
    }
   ],
   "source": [
    "# New Hyperparameters\n",
    "# Reference: Supported channels by algorithm\n",
    "#   https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
    "estimator.fit({'train':s3_training_file_location, 'test': s3_test_file_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# Ref: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.m4.xlarge',\n",
    "                             endpoint_name = 'fm-movie-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Predictions\n",
    "\n",
    "### Dense and Sparse Formats\n",
    "\n",
    "Ref: [Common Data Formats for Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.predictor import json_deserializer\n",
    "\n",
    "def fm_sparse_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        \n",
    "        column_list = row.tolist()\n",
    "        value_list = np.ones(len(column_list),dtype=int).tolist()\n",
    "       \n",
    "        js['instances'].append({'data':{'features': { 'keys': column_list, 'shape':[dim_movie], 'values': value_list}}})\n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.content_type = 'application/json'\n",
    "predictor.serializer = fm_sparse_serializer\n",
    "predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"data\": {\"features\": {\"keys\": [341, 1416], \"shape\": [10334], \"values\": [1, 1]}}}]}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_sparse_serializer([np.array([341,1416])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '561:1', '2822:1']\n",
      "***Actual Rating: 4\n",
      "***Predicted Rating: {'predictions': [{'score': 3.306558609008789}]}\n",
      "['3.5', '473:1', '2600:1']\n",
      "***Actual Rating: 3.5\n",
      "***Predicted Rating: {'predictions': [{'score': 3.339083433151245}]}\n",
      "['4.5', '361:1', '2548:1']\n",
      "***Actual Rating: 4.5\n",
      "***Predicted Rating: {'predictions': [{'score': 4.247658729553223}]}\n"
     ]
    }
   ],
   "source": [
    "# Let's test with few entries from test file\n",
    "# Movie dataset is updated regularly...so, instead of hard coding userid and movie id, let's\n",
    "# use actual values\n",
    "\n",
    "# Each row is in this format: ['2.5', '426:1', '943:1']\n",
    "# ActualRating, UserID, MovieID\n",
    "\n",
    "with open(r'ml-latest-small/user_movie_test.svm','r') as f:\n",
    "    for i in range(3):\n",
    "        rating = f.readline().split()\n",
    "        print(rating)\n",
    "        print ('***Actual Rating:',rating[0])\n",
    "        # UserID, MovieID\n",
    "        userID = rating[1].split(':')[0]\n",
    "        movieID = rating[2].split(':')[0]\n",
    "        predicted_rating = predictor.predict([np.array([int(userID),int(movieID)])])\n",
    "        print('***Predicted Rating:', predicted_rating)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
